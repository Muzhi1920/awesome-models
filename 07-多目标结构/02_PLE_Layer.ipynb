{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_PLE_Layer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM+zWp+pNZPEbFn/jq2r9mA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muzhi1920/awesome-models/blob/main/07-%E5%A4%9A%E7%9B%AE%E6%A0%87%E7%BB%93%E6%9E%84/02_PLE_Layer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0VWrWAZsxMI"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import feature_column as fc\n",
        "from tensorflow.keras import initializers, regularizers, constraints, activations\n",
        "from tensorflow.keras.layers import Layer, InputSpec, Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5reWJEluBxk"
      },
      "source": [
        "## 0.准备工作"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUOCHmuos08Z",
        "outputId": "83153b10-cd36-4f34-9aea-a45851c2c955"
      },
      "source": [
        "nums = fc.numeric_column('nums', dtype=tf.float32)\n",
        "seq = fc.categorical_column_with_hash_bucket('seq', hash_bucket_size=10, dtype=tf.int64)\n",
        "target = fc.categorical_column_with_hash_bucket('target', hash_bucket_size=10, dtype=tf.int64)\n",
        "seq_col = fc.embedding_column(seq, dimension=8)\n",
        "target_col = fc.embedding_column(target, dimension=8)\n",
        "columns = [seq_col, target_col, nums]\n",
        "features={\n",
        "    \"seq\": tf.sparse.SparseTensor(\n",
        "        indices=[[0, 0], [0, 1], [1, 0], [1, 1], [2, 0]],\n",
        "        values=[1100, 1101, 1102, 1101, 1103],\n",
        "        dense_shape=[3, 2]),\n",
        "    \"target\": tf.sparse.SparseTensor(\n",
        "        indices=[[0, 0],[1,0],[2,0]],\n",
        "        values=[1102,1103,1100],\n",
        "        dense_shape=[3, 1]),\n",
        "    \"nums\": tf.convert_to_tensor([0.1,0.2,0.3]) \n",
        "\n",
        "}\n",
        "tf.sparse.to_dense(features['seq'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              "array([[1100, 1101],\n",
              "       [1102, 1101],\n",
              "       [1103,    0]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubwiS-lCs05a",
        "outputId": "9fd2f1c1-a39c-4e62-89a8-aad271e9e511"
      },
      "source": [
        "input_layer = tf.keras.layers.DenseFeatures(columns, name='features_input_layer')\n",
        "net = input_layer(features)\n",
        "#tf.concat(sequence_inputs.values(), axis =-1)\n",
        "net"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 17), dtype=float32, numpy=\n",
              "array([[ 0.1       ,  0.368285  ,  0.01953911,  0.329111  , -0.28448862,\n",
              "         0.00381372, -0.1794903 , -0.06729466,  0.10163559, -0.36710843,\n",
              "        -0.47717634,  0.2626422 ,  0.40373984,  0.48506886,  0.4386921 ,\n",
              "         0.2912761 , -0.08068093],\n",
              "       [ 0.2       ,  0.18373841,  0.3408668 ,  0.35096297,  0.10208823,\n",
              "        -0.0336121 , -0.11717728,  0.24010646,  0.35366982, -0.17428383,\n",
              "         0.18445659, -0.61224234,  0.32126307,  0.35839644, -0.2370223 ,\n",
              "         0.05115302,  0.3337443 ],\n",
              "       [ 0.3       ,  0.14535068, -0.12395273,  0.1549992 , -0.56996447,\n",
              "         0.22735709, -0.59369177, -0.2510585 , -0.1254943 ,  0.09329653,\n",
              "         0.0244523 , -0.5612847 ,  0.29976568, -0.03937777, -0.51279557,\n",
              "         0.08720471, -0.23819971]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ST5Fzz-uGUE"
      },
      "source": [
        "## 1.PLE Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_z_ATNOs01O"
      },
      "source": [
        "class PLELayer(Layer):\n",
        "    def __init__(self,\n",
        "                 tower_task_specs,\n",
        "                 experts_network,\n",
        "                 num_share_experts,\n",
        "                 num_tasks,\n",
        "                 multi_level,\n",
        "                 use_expert_bias=True,\n",
        "                 use_gate_bias=True,\n",
        "                 expert_activation='relu',\n",
        "                 gate_activation='softmax',\n",
        "                 expert_bias_initializer='zeros',\n",
        "                 gate_bias_initializer='zeros',\n",
        "                 expert_bias_regularizer=None,\n",
        "                 gate_bias_regularizer=None,\n",
        "                 expert_bias_constraint=None,\n",
        "                 gate_bias_constraint=None,\n",
        "                 expert_kernel_initializer='VarianceScaling',\n",
        "                 gate_kernel_initializer='VarianceScaling',\n",
        "                 expert_kernel_regularizer=None,\n",
        "                 gate_kernel_regularizer=None,\n",
        "                 expert_kernel_constraint=None,\n",
        "                 gate_kernel_constraint=None,\n",
        "                 activity_regularizer=None,\n",
        "                 **kwargs):\n",
        "        \"\"\"\n",
        "         Method for instantiating MMoE layer.\n",
        "        :param tower_task_specs: Config of every task\n",
        "        :param experts_network: hidden_layers in expert within last units\n",
        "        :param num_share_experts: Number of experts for share task\n",
        "        :param num_tasks: Number of tasks\n",
        "        :param multi_level: Level number in PLE structure\n",
        "        :param use_expert_bias: Boolean to indicate the usage of bias in the expert weights\n",
        "        :param use_gate_bias: Boolean to indicate the usage of bias in the gate weights\n",
        "        :param expert_activation: Activation function of the expert weights\n",
        "        :param gate_activation: Activation function of the gate weights\n",
        "        :param expert_bias_initializer: Initializer for the expert bias\n",
        "        :param gate_bias_initializer: Initializer for the gate bias\n",
        "        :param expert_bias_regularizer: Regularizer for the expert bias\n",
        "        :param gate_bias_regularizer: Regularizer for the gate bias\n",
        "        :param expert_bias_constraint: Constraint for the expert bias\n",
        "        :param gate_bias_constraint: Constraint for the gate bias\n",
        "        :param expert_kernel_initializer: Initializer for the expert weights\n",
        "        :param gate_kernel_initializer: Initializer for the gate weights\n",
        "        :param expert_kernel_regularizer: Regularizer for the expert weights\n",
        "        :param gate_kernel_regularizer: Regularizer for the gate weights\n",
        "        :param expert_kernel_constraint: Constraint for the expert weights\n",
        "        :param gate_kernel_constraint: Constraint for the gate weights\n",
        "        :param activity_regularizer: Regularizer for the activity\n",
        "        :param kwargs: Additional keyword arguments for the Layer class\n",
        "        \"\"\"\n",
        "        assert experts_network is not None\n",
        "        assert num_share_experts is not None and num_share_experts > 0\n",
        "        assert num_tasks is not None and num_tasks > 0\n",
        "        assert multi_level is not None and multi_level > 0\n",
        "\n",
        "        # Hidden nodes parameter\n",
        "        self.multi_level = multi_level\n",
        "        self.num_tasks = num_tasks\n",
        "        self.tower_task_specs = tower_task_specs\n",
        "        self.num_share_experts = num_share_experts\n",
        "        self.experts_network = experts_network\n",
        "\n",
        "        # Weight parameter\n",
        "        self.expert_kernel_initializer = initializers.get(expert_kernel_initializer)\n",
        "        self.gate_kernel_initializer = initializers.get(gate_kernel_initializer)\n",
        "        self.expert_kernel_regularizer = regularizers.get(expert_kernel_regularizer)\n",
        "        self.gate_kernel_regularizer = regularizers.get(gate_kernel_regularizer)\n",
        "        self.expert_kernel_constraint = constraints.get(expert_kernel_constraint)\n",
        "        self.gate_kernel_constraint = constraints.get(gate_kernel_constraint)\n",
        "\n",
        "        # Activation parameter\n",
        "        self.expert_activation = activations.get(expert_activation)\n",
        "        self.gate_activation = activations.get(gate_activation)\n",
        "\n",
        "        # Bias parameter\n",
        "        self.use_expert_bias = use_expert_bias\n",
        "        self.use_gate_bias = use_gate_bias\n",
        "        self.expert_bias_initializer = initializers.get(expert_bias_initializer)\n",
        "        self.gate_bias_initializer = initializers.get(gate_bias_initializer)\n",
        "        self.expert_bias_regularizer = regularizers.get(expert_bias_regularizer)\n",
        "        self.gate_bias_regularizer = regularizers.get(gate_bias_regularizer)\n",
        "        self.expert_bias_constraint = constraints.get(expert_bias_constraint)\n",
        "        self.gate_bias_constraint = constraints.get(gate_bias_constraint)\n",
        "\n",
        "        # Activity parameter\n",
        "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "\n",
        "        # Keras parameter\n",
        "        self.input_spec = InputSpec(min_ndim=2)\n",
        "        self.supports_masking = True\n",
        "\n",
        "        super(PLELayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"\n",
        "        Method for creating the layer weights.\n",
        "\n",
        "        :param input_shape: Keras tensor (future input to layer)\n",
        "                            or list/tuple of Keras tensors to reference\n",
        "                            for weight shape computations\n",
        "        \"\"\"\n",
        "        assert input_shape is not None and len(input_shape) >= 2\n",
        "\n",
        "        input_dimension = input_shape[-1]\n",
        "\n",
        "        # build for all level expert kernels\n",
        "        # 1 level     kernel:512,[256,128,5] == output\n",
        "        # >1 level    kernel:512,[256,128,5] * (level - 1) -> output\n",
        "        for level in range(self.multi_level):\n",
        "            # build for spec experts\n",
        "            for k, tower in enumerate(self.tower_task_specs):\n",
        "                for s in range(tower['spec_expert']):\n",
        "                    for index, num_node in enumerate(self.experts_network):\n",
        "                        setattr(self, 'multi_extraction_level_{}_task_{}_spec_{}_index_{}'.format(level, k, s, index),\n",
        "                                Dense(num_node, activation='relu', kernel_initializer=self.expert_kernel_initializer,\n",
        "                                      kernel_regularizer=self.expert_kernel_regularizer, kernel_constraint=self.expert_kernel_constraint,\n",
        "                                      name='multi_extraction_level_{}_task_{}_spec_{}_index_{}'.format(level, k, s, index)))\n",
        "            # build for share experts\n",
        "            for sh in range(self.num_share_experts):\n",
        "                for index, num_node in enumerate(self.experts_network):\n",
        "                    setattr(self, 'multi_extraction_level_{}_share_{}_index_{}'.format(level, sh, index),\n",
        "                            Dense(num_node, activation='relu', kernel_initializer=self.expert_kernel_initializer,\n",
        "                                  kernel_regularizer=self.expert_kernel_regularizer, kernel_constraint=self.expert_kernel_constraint,\n",
        "                                  name='multi_extraction_level_{}_share_{}_index_{}'.format(level, sh, index)))\n",
        "\n",
        "        # build for all level gate\n",
        "        # last level;   gate 3, 3, 3\n",
        "        # other level;  gate 3, 3, 3, 5\n",
        "        for level in range(self.multi_level):\n",
        "            # build for gate kernel for task spec (spec_expert + num_share_experts)\n",
        "            for k, tower in enumerate(self.tower_task_specs):\n",
        "                setattr(self, 'gate_level_{}_task_{}'.format(level, k),\n",
        "                        Dense(tower['spec_expert'] + self.num_share_experts, activation='softmax',\n",
        "                              kernel_initializer=self.gate_kernel_initializer,\n",
        "                              kernel_regularizer=self.gate_kernel_regularizer, kernel_constraint=self.gate_kernel_constraint,\n",
        "                              bias_initializer=self.gate_bias_initializer, bias_regularizer=self.gate_bias_regularizer,\n",
        "                              bias_constraint=self.gate_bias_constraint, name='gate_level_{}_task_{}'.format(level, k)))\n",
        "            # build for gate kernel for share experts (spec_expert * num_tasks + num_share_experts)\n",
        "            if level != self.multi_level - 1:\n",
        "                # build for gate kernel for share (all)\n",
        "                setattr(self, 'gate_level_{}_share'.format(level),\n",
        "                        Dense(self.tower_task_specs[0]['spec_expert'] * self.num_tasks + self.num_share_experts, activation='softmax',\n",
        "                              kernel_initializer=self.gate_kernel_initializer,\n",
        "                              kernel_regularizer=self.gate_kernel_regularizer, kernel_constraint=self.gate_kernel_constraint,\n",
        "                              bias_initializer=self.gate_bias_initializer, bias_regularizer=self.gate_bias_regularizer,\n",
        "                              bias_constraint=self.gate_bias_constraint, name='gate_level_{}_share'.format(level)))\n",
        "\n",
        "        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dimension})\n",
        "\n",
        "        super(PLELayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Method for the forward function of the layer.\n",
        "\n",
        "        :param inputs: Input tensor\n",
        "        :return: A tensor\n",
        "        \"\"\"\n",
        "\n",
        "        for level in range(self.multi_level):\n",
        "            if level == 0:\n",
        "                cur_inputs = inputs\n",
        "            else:\n",
        "                cur_inputs = level_outputs\n",
        "            experts_outputs = self.multi_level_kernel_layer(level, cur_inputs)\n",
        "            # print('level_{}_expert_outputs:{}'.format(level, experts_outputs))\n",
        "            group_multi_level_extraction_outputs = self.group_multi_extraction_expert(level, experts_outputs)\n",
        "            # print('level_{}_group_experts:{}'.format(level, group_multi_level_extraction_outputs))\n",
        "            gate_outputs = self.multi_level_extraction_gate(level, cur_inputs)\n",
        "            # print('level_{}_gate_output:{}'.format(level, gate_outputs))\n",
        "            level_outputs = self.multi_level_extraction_output_emb(level, gate_outputs, group_multi_level_extraction_outputs)\n",
        "            # print('level_{}_outputs:{}'.format(level, level_outputs))\n",
        "\n",
        "        return level_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\"\n",
        "        Method for computing the output shape of the MMoE layer.\n",
        "\n",
        "        :param input_shape: Shape tuple (tuple of integers)\n",
        "        :return: List of input shape tuple where the size of the list is equal to the number of tasks\n",
        "        \"\"\"\n",
        "        assert input_shape is not None and len(input_shape) >= 2\n",
        "\n",
        "        output_shape = list(input_shape)\n",
        "        output_shape[-1] = self.experts_network[-1]\n",
        "        output_shape = tuple(output_shape)\n",
        "\n",
        "        return tf.TensorShape([output_shape for _ in range(self.num_tasks)])\n",
        "\n",
        "    def get_config(self):\n",
        "        \"\"\"\n",
        "        Method for returning the configuration of the MMoE layer.\n",
        "\n",
        "        :return: Config dictionary\n",
        "        \"\"\"\n",
        "        cur_config = {\n",
        "            'experts_network': self.experts_network,\n",
        "            'num_experts': self.num_experts,\n",
        "            'num_tasks': self.num_tasks,\n",
        "            'use_expert_bias': self.use_expert_bias,\n",
        "            'use_gate_bias': self.use_gate_bias,\n",
        "            'expert_activation': activations.serialize(self.expert_activation),\n",
        "            'gate_activation': activations.serialize(self.gate_activation),\n",
        "            'expert_bias_initializer': initializers.serialize(self.expert_bias_initializer),\n",
        "            'gate_bias_initializer': initializers.serialize(self.gate_bias_initializer),\n",
        "            'expert_bias_regularizer': regularizers.serialize(self.expert_bias_regularizer),\n",
        "            'gate_bias_regularizer': regularizers.serialize(self.gate_bias_regularizer),\n",
        "            'expert_bias_constraint': constraints.serialize(self.expert_bias_constraint),\n",
        "            'gate_bias_constraint': constraints.serialize(self.gate_bias_constraint),\n",
        "            'expert_kernel_initializer': initializers.serialize(self.expert_kernel_initializer),\n",
        "            'gate_kernel_initializer': initializers.serialize(self.gate_kernel_initializer),\n",
        "            'expert_kernel_regularizer': regularizers.serialize(self.expert_kernel_regularizer),\n",
        "            'gate_kernel_regularizer': regularizers.serialize(self.gate_kernel_regularizer),\n",
        "            'expert_kernel_constraint': constraints.serialize(self.expert_kernel_constraint),\n",
        "            'gate_kernel_constraint': constraints.serialize(self.gate_kernel_constraint),\n",
        "            'activity_regularizer': regularizers.serialize(self.activity_regularizer)\n",
        "        }\n",
        "        config = super(PLELayer, self).get_config()\n",
        "        config.update(cur_config)\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "    # expert kernel layer: input -> multi_experts -> output_emb(None,128,1)\n",
        "    def multi_level_kernel_layer(self, level, cur_inputs):\n",
        "        experts_outputs = []\n",
        "        # forward to task spec experts\n",
        "        for k, tower in enumerate(self.tower_task_specs):\n",
        "            for s in range(tower['spec_expert']):\n",
        "                if level == 0:\n",
        "                    inputs = cur_inputs\n",
        "                else:\n",
        "                    inputs = cur_inputs[k]\n",
        "                # forward to dnn experts\n",
        "                for index, _ in enumerate(self.experts_network):\n",
        "                    net = getattr(self, 'multi_extraction_level_{}_task_{}_spec_{}_index_{}'.format(level, k, s, index))(inputs)\n",
        "                    inputs = net\n",
        "                experts_outputs.append(tf.keras.backend.expand_dims(net, axis=-1))\n",
        "        # forward to share experts\n",
        "        for sh in range(self.num_share_experts):\n",
        "            if level == 0:\n",
        "                inputs = cur_inputs\n",
        "            else:\n",
        "                inputs = cur_inputs[-1]\n",
        "            # forward to dnn experts\n",
        "            for index, _ in enumerate(self.experts_network):\n",
        "                net = getattr(self, 'multi_extraction_level_{}_share_{}_index_{}'.format(level, sh, index))(inputs)\n",
        "                inputs = net\n",
        "            experts_outputs.append(tf.keras.backend.expand_dims(net, axis=-1))\n",
        "        # print('multi_level_{}_expert_list:{}'.format(level, experts_outputs))\n",
        "        return experts_outputs\n",
        "\n",
        "    # group experts list for spec task and share task\n",
        "    def group_multi_extraction_expert(self, level, expert_output_list):\n",
        "        multi_level_extraction_outputs = []\n",
        "        share_expert_list = expert_output_list[-self.num_share_experts:]\n",
        "        # 1 group for each spec task expert\n",
        "        for index, tower in enumerate(self.tower_task_specs):\n",
        "            task_expert = [expert_output_list[index]]\n",
        "            task_expert.extend(share_expert_list)\n",
        "            task_expert = tf.concat(values=task_expert, axis=-1, name='extraction_level_{}_concat_{}'.format(level, index))\n",
        "            multi_level_extraction_outputs.append(task_expert)\n",
        "        # for last level, only group (spec expert + share_expert) for every spec task, not for share task\n",
        "        if level == self.multi_level - 1:\n",
        "            return multi_level_extraction_outputs\n",
        "\n",
        "        # 2 all expert for share\n",
        "        share_experts = tf.concat(values=expert_output_list, axis=-1, name='multi_level_extraction_share_concat_{}'.format(level))\n",
        "        multi_level_extraction_outputs.append(share_experts)\n",
        "        return multi_level_extraction_outputs\n",
        "\n",
        "    # expert gate kenel: input -> gate_kernel -> gate [(None,3),(None,3),(None,3),(None,4),(None,4)]\n",
        "    def multi_level_extraction_gate(self, level, cur_inputs):\n",
        "        gate_outputs = []\n",
        "        # 1. cal for task_experts_group gate\n",
        "        for k, tower in enumerate(self.tower_task_specs):\n",
        "            if level == 0:\n",
        "                inputs = cur_inputs\n",
        "            else:\n",
        "                inputs = cur_inputs[k]\n",
        "            spec_gate_output = getattr(self, 'gate_level_{}_task_{}'.format(level, k))(inputs)\n",
        "            gate_outputs.append(spec_gate_output)\n",
        "        # 2. cal for share_experts_group gate except for last level\n",
        "        if level != self.multi_level - 1:\n",
        "            if level == 0:\n",
        "                inputs = cur_inputs\n",
        "            else:\n",
        "                inputs = cur_inputs[-1]\n",
        "            share_gate_output = getattr(self, 'gate_level_{}_share'.format(level))(inputs)\n",
        "            gate_outputs.append(share_gate_output)\n",
        "        return gate_outputs\n",
        "\n",
        "    # gate * experts_list = weighted emb\n",
        "    def multi_level_extraction_output_emb(self, level, input_extraction_gate_list, input_extraction_expert_list):\n",
        "        outputs = []\n",
        "        for index, (gate_output, task_expert) in enumerate(zip(input_extraction_gate_list, input_extraction_expert_list)):\n",
        "            # print('gate_output_level_{}_index_{}:{}'.format(level, index, gate_output))\n",
        "            expanded_gate_output = tf.keras.backend.expand_dims(gate_output, axis=1)\n",
        "            # print('expanded_gate_output_level_{}_index_{}:{}'.format(level, index, expanded_gate_output))\n",
        "            repeated_gate_output = tf.keras.backend.repeat_elements(expanded_gate_output, self.experts_network[-1], axis=1)\n",
        "            # print('repeated_expanded_gate_output_level_{}_index_{}:{}'.format(level, index, repeated_gate_output))\n",
        "            weighted_expert_output = task_expert * repeated_gate_output\n",
        "            # print('weighted_repeated_expanded_gate_output_level_{}_index_{}:{}'.format(level, index, weighted_expert_output))\n",
        "            outputs.append(tf.keras.backend.sum(weighted_expert_output, axis=2))\n",
        "        # print('multi_level_{}_extraction_outputs_emb:{}'.format(level, outputs))\n",
        "        return outputs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lyRz7c2s0wZ",
        "outputId": "e18def84-7c21-450e-c06c-26ec50e61b54"
      },
      "source": [
        "tower_task_specs = [{'task': 'A', 'spec_expert': 1},\n",
        "                    {'task': 'B', 'spec_expert': 1},\n",
        "                    {'task': 'C', 'spec_expert': 1}]\n",
        "\n",
        "experts_network = [64, 64]\n",
        "\n",
        "num_share_experts = 2\n",
        "\n",
        "multi_level = 1\n",
        "\n",
        "ple_layer = PLELayer(tower_task_specs=tower_task_specs, experts_network=experts_network, num_share_experts=num_share_experts, multi_level=multi_level, num_tasks=len(tower_task_specs))\n",
        "ple_layer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.PLELayer at 0x7fcd2ef15190>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgOPZZi_s0uE",
        "outputId": "691e268b-8f21-4e4d-cffc-3dbb3197ec3b"
      },
      "source": [
        "ple_layer(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(3, 64), dtype=float32, numpy=\n",
              " array([[0.00633524, 0.25465465, 0.05535328, 0.02153273, 0.12176438,\n",
              "         0.02236252, 0.07568981, 0.24306658, 0.1214754 , 0.25624943,\n",
              "         0.05656353, 0.12924038, 0.08294437, 0.08587804, 0.20312986,\n",
              "         0.07619958, 0.02773911, 0.09143917, 0.16418178, 0.18385105,\n",
              "         0.1264493 , 0.14429104, 0.03289412, 0.10242222, 0.04664102,\n",
              "         0.04787858, 0.        , 0.09632555, 0.10831477, 0.078369  ,\n",
              "         0.04134453, 0.08651172, 0.10960472, 0.0883157 , 0.09873402,\n",
              "         0.05162107, 0.02600574, 0.        , 0.0045758 , 0.16982089,\n",
              "         0.09039186, 0.14455765, 0.13831814, 0.03501253, 0.0490548 ,\n",
              "         0.06739961, 0.10657761, 0.14929184, 0.09703999, 0.07625906,\n",
              "         0.04855544, 0.        , 0.10651408, 0.08478894, 0.08451825,\n",
              "         0.20067537, 0.        , 0.05383517, 0.00217588, 0.        ,\n",
              "         0.00964267, 0.        , 0.        , 0.24365865],\n",
              "        [0.1083691 , 0.21220192, 0.02622489, 0.08850792, 0.07212117,\n",
              "         0.04345309, 0.06849354, 0.09016161, 0.06230221, 0.07258753,\n",
              "         0.0508756 , 0.14160286, 0.05355012, 0.03199365, 0.05863027,\n",
              "         0.04980146, 0.06241627, 0.00370517, 0.05849   , 0.01047204,\n",
              "         0.04782732, 0.20634736, 0.02883219, 0.02373567, 0.13583194,\n",
              "         0.03351046, 0.09478684, 0.01545759, 0.01514167, 0.09431355,\n",
              "         0.05336718, 0.03374593, 0.098684  , 0.        , 0.03580861,\n",
              "         0.05077124, 0.17263114, 0.01224313, 0.        , 0.13094679,\n",
              "         0.        , 0.03039604, 0.03361017, 0.06911547, 0.0982963 ,\n",
              "         0.01619276, 0.07925223, 0.20612459, 0.14561255, 0.        ,\n",
              "         0.10015176, 0.0323717 , 0.07058391, 0.22891003, 0.12428899,\n",
              "         0.03769194, 0.02810715, 0.23306271, 0.        , 0.        ,\n",
              "         0.06948885, 0.        , 0.01895444, 0.03634803],\n",
              "        [0.18817176, 0.26898968, 0.03358815, 0.0461258 , 0.0993897 ,\n",
              "         0.08769516, 0.00546223, 0.22726092, 0.16416739, 0.05318692,\n",
              "         0.09032093, 0.05982245, 0.06254319, 0.03561001, 0.        ,\n",
              "         0.19489492, 0.10425629, 0.00365368, 0.        , 0.06224642,\n",
              "         0.02693463, 0.21736911, 0.04805045, 0.        , 0.1188656 ,\n",
              "         0.12038078, 0.0431834 , 0.03692346, 0.02434644, 0.21560559,\n",
              "         0.03842544, 0.        , 0.07722366, 0.09586994, 0.        ,\n",
              "         0.09597484, 0.21668145, 0.00086239, 0.08871568, 0.04140485,\n",
              "         0.15609966, 0.2431341 , 0.19744098, 0.27412674, 0.03719556,\n",
              "         0.11041622, 0.00851067, 0.17952842, 0.20796625, 0.00322667,\n",
              "         0.0847754 , 0.        , 0.03017654, 0.15310258, 0.1069294 ,\n",
              "         0.03081639, 0.02311293, 0.10608002, 0.        , 0.        ,\n",
              "         0.08110865, 0.        , 0.06513907, 0.08853447]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 64), dtype=float32, numpy=\n",
              " array([[0.        , 0.1448987 , 0.0367449 , 0.02317541, 0.09120706,\n",
              "         0.01484481, 0.08192419, 0.1828382 , 0.09537378, 0.22338541,\n",
              "         0.01360283, 0.04693602, 0.0722174 , 0.0446349 , 0.17736287,\n",
              "         0.01359055, 0.03369421, 0.09460061, 0.20117903, 0.14088117,\n",
              "         0.06183822, 0.05044354, 0.02907554, 0.06799045, 0.        ,\n",
              "         0.07142836, 0.        , 0.07582885, 0.1623251 , 0.08434759,\n",
              "         0.035327  , 0.22320132, 0.14967604, 0.05862619, 0.08717623,\n",
              "         0.10440864, 0.1392223 , 0.        , 0.0569151 , 0.00038117,\n",
              "         0.03727211, 0.09845133, 0.14887011, 0.03041398, 0.02629055,\n",
              "         0.00050126, 0.0707489 , 0.05352017, 0.1803591 , 0.02653173,\n",
              "         0.19852293, 0.        , 0.05719335, 0.02386978, 0.05610534,\n",
              "         0.20508897, 0.        , 0.02532837, 0.        , 0.        ,\n",
              "         0.05604066, 0.        , 0.        , 0.26526076],\n",
              "        [0.06501332, 0.06213565, 0.02987086, 0.11194463, 0.08399267,\n",
              "         0.05305403, 0.08487464, 0.0254022 , 0.0709639 , 0.23579237,\n",
              "         0.        , 0.11605967, 0.04161736, 0.        , 0.06678148,\n",
              "         0.0700786 , 0.17466217, 0.02697595, 0.14279541, 0.        ,\n",
              "         0.10066714, 0.06600742, 0.        , 0.02977323, 0.1667414 ,\n",
              "         0.09711546, 0.05569598, 0.12732184, 0.01899321, 0.16884993,\n",
              "         0.05762241, 0.1605282 , 0.15763804, 0.        , 0.07420634,\n",
              "         0.05782982, 0.18741962, 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.03462191, 0.07760227, 0.0787244 , 0.04810021,\n",
              "         0.02031165, 0.15563625, 0.1174657 , 0.15999438, 0.08450707,\n",
              "         0.07103347, 0.        , 0.08288908, 0.02963652, 0.13875085,\n",
              "         0.07227333, 0.03525667, 0.09953677, 0.03208455, 0.        ,\n",
              "         0.12425515, 0.        , 0.02377581, 0.17037538],\n",
              "        [0.213907  , 0.19220433, 0.04036139, 0.12713937, 0.12038592,\n",
              "         0.02115086, 0.07338288, 0.13976479, 0.05918063, 0.0714279 ,\n",
              "         0.12227708, 0.05610367, 0.07515538, 0.02973293, 0.        ,\n",
              "         0.08808711, 0.1248446 , 0.00305067, 0.0157815 , 0.06868486,\n",
              "         0.        , 0.09395068, 0.05632341, 0.        , 0.10216738,\n",
              "         0.13296583, 0.07926711, 0.08827665, 0.0510963 , 0.11178338,\n",
              "         0.05111579, 0.05203137, 0.06447865, 0.09020496, 0.        ,\n",
              "         0.08013514, 0.20749232, 0.02499622, 0.07407403, 0.01996093,\n",
              "         0.11030436, 0.17995512, 0.26259077, 0.21991155, 0.        ,\n",
              "         0.085465  , 0.10446057, 0.07602438, 0.25313812, 0.        ,\n",
              "         0.        , 0.03890188, 0.07491469, 0.07163091, 0.13449527,\n",
              "         0.04289231, 0.04229983, 0.07926543, 0.03058789, 0.        ,\n",
              "         0.1276853 , 0.        , 0.1015598 , 0.07392273]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 64), dtype=float32, numpy=\n",
              " array([[0.00000000e+00, 1.79663792e-01, 2.64008585e-02, 3.44047472e-02,\n",
              "         1.09616049e-01, 6.02509379e-02, 1.19994141e-01, 3.13148946e-01,\n",
              "         1.09458432e-01, 2.24363491e-01, 1.27524599e-01, 6.23916760e-02,\n",
              "         1.20556444e-01, 7.25651532e-02, 3.35015535e-01, 4.83959131e-02,\n",
              "         4.99762408e-02, 4.36120965e-02, 1.70522720e-01, 2.33645111e-01,\n",
              "         8.94939080e-02, 0.00000000e+00, 0.00000000e+00, 1.09791815e-01,\n",
              "         0.00000000e+00, 1.79823227e-02, 1.45578176e-01, 1.96241826e-01,\n",
              "         1.34431794e-01, 1.25217095e-01, 1.90300211e-01, 1.64894328e-01,\n",
              "         5.22761941e-02, 4.21223529e-02, 1.48014680e-01, 2.46207733e-02,\n",
              "         0.00000000e+00, 8.38025436e-02, 7.18844384e-02, 2.73869198e-04,\n",
              "         2.98827235e-02, 1.64595976e-01, 3.60447526e-01, 1.38995558e-01,\n",
              "         1.88895054e-02, 7.44132907e-04, 5.08323982e-02, 3.84537280e-02,\n",
              "         4.62834165e-02, 1.66568011e-01, 1.64579287e-01, 0.00000000e+00,\n",
              "         6.24918453e-02, 1.71502028e-02, 4.03111465e-02, 1.02136835e-01,\n",
              "         1.53261970e-03, 3.76008973e-02, 1.39639035e-01, 0.00000000e+00,\n",
              "         7.45434612e-02, 1.60184607e-01, 4.44663465e-02, 2.85581321e-01],\n",
              "        [6.49737716e-02, 5.05547151e-02, 1.25284940e-01, 9.92111862e-02,\n",
              "         7.24160299e-02, 4.41396013e-02, 1.15870446e-01, 1.07025817e-01,\n",
              "         6.25569224e-02, 8.39565545e-02, 0.00000000e+00, 9.53521207e-02,\n",
              "         1.27062231e-01, 0.00000000e+00, 5.88699766e-02, 1.34116054e-01,\n",
              "         6.21960312e-02, 1.19981887e-02, 7.99653232e-02, 0.00000000e+00,\n",
              "         0.00000000e+00, 2.11568475e-02, 0.00000000e+00, 2.42240503e-02,\n",
              "         1.58981323e-01, 4.32900600e-02, 5.73533364e-02, 7.03596696e-02,\n",
              "         1.73206151e-01, 9.52011645e-02, 9.44598839e-02, 4.02019806e-02,\n",
              "         1.00420192e-01, 1.69301461e-02, 2.12027295e-03, 1.60407811e-01,\n",
              "         1.14240319e-01, 3.63409705e-02, 1.87819973e-02, 2.83502452e-02,\n",
              "         0.00000000e+00, 3.05203106e-02, 3.43017243e-02, 1.84772015e-01,\n",
              "         3.91352251e-02, 1.65259354e-02, 8.07879642e-02, 2.51472414e-01,\n",
              "         1.53124899e-01, 5.79717457e-02, 3.20001021e-02, 0.00000000e+00,\n",
              "         1.71029776e-01, 1.00586616e-01, 1.16145879e-01, 8.19661748e-03,\n",
              "         9.95324403e-02, 8.65089893e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         1.09524041e-01, 8.63692686e-02, 1.93444435e-02, 1.86831847e-01],\n",
              "        [9.67844278e-02, 2.49188572e-01, 7.29716420e-02, 1.43104404e-01,\n",
              "         6.34738356e-02, 2.20522523e-01, 1.80877075e-01, 7.88855702e-02,\n",
              "         2.53005270e-02, 1.69790890e-02, 5.70305698e-02, 3.77731733e-02,\n",
              "         1.80847138e-01, 7.48121589e-02, 1.34965315e-01, 5.41212782e-02,\n",
              "         4.46531810e-02, 2.30700895e-03, 1.17080234e-01, 1.09813213e-01,\n",
              "         0.00000000e+00, 7.13716522e-02, 2.46726852e-02, 0.00000000e+00,\n",
              "         8.74285847e-02, 4.62639183e-02, 6.87279105e-02, 1.80029348e-01,\n",
              "         2.07873702e-01, 5.53789586e-02, 3.18765581e-01, 7.99699351e-02,\n",
              "         4.87606674e-02, 6.05343319e-02, 0.00000000e+00, 6.06005639e-02,\n",
              "         1.86682791e-01, 1.83618844e-01, 5.60169779e-02, 6.96550831e-02,\n",
              "         8.34154189e-02, 1.65223420e-01, 1.26097485e-01, 3.41190994e-01,\n",
              "         0.00000000e+00, 5.21393344e-02, 5.50735323e-03, 3.95590700e-02,\n",
              "         1.01397581e-01, 5.95954135e-02, 0.00000000e+00, 0.00000000e+00,\n",
              "         9.21189189e-02, 4.20959294e-02, 6.82436675e-02, 1.46293472e-02,\n",
              "         1.20046334e-02, 7.91255534e-02, 2.13195279e-01, 9.04183015e-02,\n",
              "         2.81873252e-02, 1.08253323e-01, 4.11302038e-02, 3.51897210e-01]],\n",
              "       dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKbM3AU-s0r6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7smeU59s0pk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}