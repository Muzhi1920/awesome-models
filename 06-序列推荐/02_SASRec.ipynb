{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_SASRec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPj0SSr33yPgNS7XcmDkUJb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muzhi1920/awesome-models/blob/main/06-%E5%BA%8F%E5%88%97%E6%8E%A8%E8%8D%90/02_SASRec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE_LD-3E3Aa7"
      },
      "source": [
        "# SASRec\n",
        "\n",
        "应用self-attention做序列推荐。\n",
        "\n",
        "1. 基于马尔可夫的方法，通过简单的假设，学习状态转移；**高维稀疏数据下表现较好，但复杂样本中捕捉信息能力较差**\n",
        "2. 基于RNN的方法需要样本较多，稠密数据下效果较好，但效率较低。\n",
        "\n",
        "序列的自注意力机制：连续输出依赖于连续输入的相关信息，这些输入的作用更需要关注。\n",
        "\n",
        "\n",
        "- 变长seq的Embedding表示：左侧填充零向量；\n",
        "- 位置编码：Trm自身无位置信息；位置的重要性，分不同场景需要尝试；\n",
        "- $Q_i K^T_j$的计算中，i<j时，存在序列穿越的现象，**强**序列推荐需要禁止这种“穿越交互”；具体操作是使用对角阵，右上角(前对后的交互)置0，保留左下角（后对前的交互）。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnFalYN7swAy"
      },
      "source": [
        "1. 推荐场景（电商等）——>序列强相关——>（pos_emb + 禁止穿越）\n",
        "2. 推荐场景（信息流等）——>序列弱相关——>（pos_emb/穿越，需尝试）——>去掉后退化为特征交叉，兴趣提取。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQh4RLBI24x5"
      },
      "source": [
        "import tensorflow as tf\n",
        "from sequence_feature_layer import SequenceFeatures\n",
        "from tensorflow import feature_column as fc\n",
        "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout, Embedding, Conv1D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inIDY3sB3nPi"
      },
      "source": [
        "## 0.准备工作"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3VLrdbJ31cH"
      },
      "source": [
        "### 0.1定义feature_column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEMK7Pxs3M-O"
      },
      "source": [
        "num_heads = 4\n",
        "batch_size = 3\n",
        "seq_len = 2+1 # seq_nums_feed + target_feed\n",
        "emb_dims = 64\n",
        "att_hidden = 16\n",
        "out_dims = 64\n",
        "# multi_head_attention计算的维度=emb_dims / num_heads，因此固定一个即可。\n",
        "# 另一个需要确定的是ffn_output_dims"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffaRA6rp3yzv",
        "outputId": "96d4e792-87cb-4da3-df91-53bfb69bf4d5"
      },
      "source": [
        "seq = fc.sequence_categorical_column_with_hash_bucket('seq', hash_bucket_size=10, dtype=tf.int64)\n",
        "target = fc.sequence_categorical_column_with_hash_bucket('target', hash_bucket_size=10, dtype=tf.int64)\n",
        "seq_col = fc.embedding_column(seq, dimension=emb_dims)\n",
        "target_col = fc.embedding_column(target, dimension=emb_dims)\n",
        "columns = [seq_col, target_col]\n",
        "features={\n",
        "  \"seq\": tf.sparse.SparseTensor(\n",
        "      indices=[[0, 0], [0, 1], [1, 0], [1, 1], [2, 0]],\n",
        "      values=[1100, 1101, 1102, 1101, 1103],\n",
        "      dense_shape=[3, 2]),\n",
        "  \"target\": tf.sparse.SparseTensor(\n",
        "      indices=[[0, 0],[1,0],[2,0]],\n",
        "      values=[1102,1103,1100],\n",
        "      dense_shape=[3, 1]),\n",
        "\n",
        "}\n",
        "tf.sparse.to_dense(features['seq'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              "array([[1100, 1101],\n",
              "       [1102, 1101],\n",
              "       [1103,    0]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R1YJW9g4IrF"
      },
      "source": [
        "### 0.2 定义input_layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDrI3Gc13_Uq",
        "outputId": "c2b06b27-2d32-4df3-f9e5-48e28aa42f30"
      },
      "source": [
        "sequence_feature_layer = SequenceFeatures(columns, name='sequence_features_input_layer')\n",
        "sequence_inputs, sequence_lengths = sequence_feature_layer(features)\n",
        "target_input=sequence_inputs['target_embedding']\n",
        "target_length=sequence_lengths['target_embedding']\n",
        "sequence_input=sequence_inputs['seq_embedding']\n",
        "sequence_length=sequence_lengths['seq_embedding']\n",
        "tf.shape(sequence_input),sequence_length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 3,  2, 64], dtype=int32)>,\n",
              " <tf.Tensor: shape=(3,), dtype=int64, numpy=array([2, 2, 1])>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZsfsifP4Ttx"
      },
      "source": [
        "## 1.拼接序列，与mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKRf79xs4fvw",
        "outputId": "e043f019-155f-403c-f894-4c665822b361"
      },
      "source": [
        "x_= sequence_input\n",
        "tf.shape(x_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 3,  2, 64], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPUiH-I44ORa",
        "outputId": "9e11f6bc-49f6-471d-e975-bde438e5a820"
      },
      "source": [
        "seq_mask = tf.expand_dims(tf.where(tf.sequence_mask(sequence_length),1.0,0.0),axis=-1)\n",
        "mask_ = seq_mask\n",
        "mask_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2, 1), dtype=float32, numpy=\n",
              "array([[[1.],\n",
              "        [1.]],\n",
              "\n",
              "       [[1.],\n",
              "        [1.]],\n",
              "\n",
              "       [[1.],\n",
              "        [0.]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCq-vWkd4nXI"
      },
      "source": [
        "## 2.序列位置编码"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxSKhprL4cmS",
        "outputId": "9bf9b437-69cb-4d96-fd94-47eb85bbb4e2"
      },
      "source": [
        "pos_encoding = tf.keras.layers.Embedding(\n",
        "    input_dim=seq_len,\n",
        "    output_dim=emb_dims,\n",
        "    name=\"position_embedding\")\n",
        "positions = tf.range(start=0, limit= tf.shape(x_)[1], delta=1)\n",
        "tf.shape(positions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1,), dtype=int32, numpy=array([2], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm1bJ4545jOo",
        "outputId": "72503a94-1810-45f3-b65a-4142376b3948"
      },
      "source": [
        "x = x_ + tf.expand_dims(pos_encoding(positions), 0)\n",
        "tf.shape(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 3,  2, 64], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXLdjGLV6D67"
      },
      "source": [
        "### 2.1 校验位置编码"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7quvmID6BNg",
        "outputId": "d0711e9e-b3f6-49cf-e600-8f49445ae38a"
      },
      "source": [
        "x_[:,0] + pos_encoding(0)==x[:,0]# ,x_[:,1] + pos_encoding(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 64), dtype=bool, numpy=\n",
              "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True]])>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4INTvrioq5K"
      },
      "source": [
        "### 2.2 dropout与mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0WlNZW4oxHQ",
        "outputId": "0105c724-1f1e-400e-b25d-96d485065852"
      },
      "source": [
        "input_dropout=tf.keras.layers.Dropout(0.1)\n",
        "xx = input_dropout(x, training=True) * mask_\n",
        "tf.shape(xx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 3,  2, 64], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i9sd1QGoxDn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2LLPJM86qBt"
      },
      "source": [
        "## 3.multi_head_attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imiB1x9e61Nj"
      },
      "source": [
        "### 3.1初始化Wq，Wk，Wv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkOFDYk36JBs"
      },
      "source": [
        "wq = tf.random.uniform(shape=[emb_dims, num_heads * att_hidden], minval=0, maxval=1, dtype=tf.float32, seed=7)\n",
        "wk= tf.random.uniform(shape=[emb_dims, num_heads * att_hidden], minval=0, maxval=1, dtype=tf.float32, seed=7)\n",
        "wv = tf.random.uniform(shape=[emb_dims, num_heads * att_hidden], minval=0, maxval=1, dtype=tf.float32, seed=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3RkR9ej7E0X",
        "outputId": "5d4d7c8a-28e0-4a47-977f-106fe895d4c2"
      },
      "source": [
        "q_ = tf.matmul(x, wq)\n",
        "k_ = tf.matmul(x, wk)\n",
        "v_ = tf.matmul(x, wv)\n",
        "tf.shape(q_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 3,  2, 64], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANYTobd37UfG"
      },
      "source": [
        "### 3.2对Q，K，V按照multi_head切分"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmnG-GAT7J9f",
        "outputId": "30992c6d-0dd6-446c-8175-4eb1b4e5b92c"
      },
      "source": [
        "def process_multi_head(emb, num_heads):\n",
        "    emb_split = tf.split(emb, num_heads, axis=2)\n",
        "    emb = tf.concat(emb_split, axis=0)\n",
        "    print(emb_split[0].shape, emb.shape)\n",
        "    return emb\n",
        "q = process_multi_head(q_, num_heads)\n",
        "k = process_multi_head(k_, num_heads)\n",
        "v = process_multi_head(v_, num_heads)\n",
        "mask_=tf.tile(mask_, multiples=[1,1,num_heads])\n",
        "mask = process_multi_head(mask_,num_heads)\n",
        "tf.shape(mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 2, 16) (12, 2, 16)\n",
            "(3, 2, 16) (12, 2, 16)\n",
            "(3, 2, 16) (12, 2, 16)\n",
            "(3, 2, 1) (12, 2, 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([12,  2,  1], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Qet8XC17wXL"
      },
      "source": [
        "### 3.3scaled_dot_product_attention计算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr-4FN7v7kV7"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask, causality=True):\n",
        "    \"\"\"\n",
        "    Attention Mechanism\n",
        "    :param q: A 3d tensor with shape of (None, seq_len, depth), depth = d_model // num_heads\n",
        "    :param k: A 3d tensor with shape of (None, seq_len, depth)\n",
        "    :param v: A 3d tensor with shape of (None, seq_len, depth)\n",
        "    :param mask:\n",
        "    :param causality: Boolean. If True, using causality, default True\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    mat_qk = tf.matmul(q, k, transpose_b=True)  # (None, seq_len, seq_len)\n",
        "    dk = tf.cast(k.shape[-1], dtype=tf.float32)\n",
        "    # Scaled\n",
        "    scaled_att_logits = mat_qk / tf.sqrt(dk)\n",
        "\n",
        "    paddings = tf.ones_like(scaled_att_logits) * (-2 ** 32 + 1)\n",
        "    # 通过赋予极小值，将softmax后均等采样\n",
        "    outputs = tf.where(tf.equal(mask, 0), paddings, scaled_att_logits)  # (None, seq_len, seq_len)\n",
        "    # Causality\n",
        "    if causality:\n",
        "        diag_vals = tf.ones_like(outputs)  # (None, seq_len, seq_len)\n",
        "        print('diag_vals is {}'.format(diag_vals))\n",
        "        masks = tf.linalg.LinearOperatorLowerTriangular(diag_vals).to_dense()  # (None, seq_len, seq_len)\n",
        "        print('masks is {}'.format(masks))\n",
        "        paddings = tf.ones_like(masks) * (-2 ** 32 + 1)\n",
        "        print('paddings is {}'.format(paddings))\n",
        "        outputs = tf.where(tf.equal(masks, 0), paddings, outputs)  # (None, seq_len, seq_len)\n",
        "        print('outputs is {}'.format(outputs))\n",
        "\n",
        "    # softmax\n",
        "    outputs = tf.nn.softmax(logits=outputs)#, axis=-1)  # (None, seq_len, seq_len)\n",
        "    print('outputs is {}'.format(outputs))\n",
        "    outputs = tf.matmul(outputs, v)  # (None, seq_len, depth)\n",
        "    print('outputs is {}'.format(outputs))\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU6fCWiF75i4",
        "outputId": "c0f32b61-208c-4f5c-f6a4-5d7979482716"
      },
      "source": [
        "outputs = scaled_dot_product_attention(q, k, v, mask)\n",
        "tf.shape(outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diag_vals is [[[1. 1.]\n",
            "  [1. 1.]]\n",
            "\n",
            " [[1. 1.]\n",
            "  [1. 1.]]\n",
            "\n",
            " [[1. 1.]\n",
            "  [1. 1.]]\n",
            "\n",
            " [[1. 1.]\n",
            "  [1. 1.]]\n",
            "\n",
            " [[1. 1.]\n",
            "  [1. 1.]]\n",
            "\n",
            " [[1. 1.]\n",
            "  [1. 1.]]\n",
            "\n",
            " [[1. 1.]\n",
            "  [1. 1.]]\n",
            "\n",
            " [[1. 1.]\n",
            "  [1. 1.]]\n",
            "\n",
            " [[1. 1.]\n",
            "  [1. 1.]]\n",
            "\n",
            " [[1. 1.]\n",
            "  [1. 1.]]\n",
            "\n",
            " [[1. 1.]\n",
            "  [1. 1.]]\n",
            "\n",
            " [[1. 1.]\n",
            "  [1. 1.]]]\n",
            "masks is [[[1. 0.]\n",
            "  [1. 1.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [1. 1.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [1. 1.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [1. 1.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [1. 1.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [1. 1.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [1. 1.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [1. 1.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [1. 1.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [1. 1.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [1. 1.]]\n",
            "\n",
            " [[1. 0.]\n",
            "  [1. 1.]]]\n",
            "paddings is [[[-4.2949673e+09 -4.2949673e+09]\n",
            "  [-4.2949673e+09 -4.2949673e+09]]\n",
            "\n",
            " [[-4.2949673e+09 -4.2949673e+09]\n",
            "  [-4.2949673e+09 -4.2949673e+09]]\n",
            "\n",
            " [[-4.2949673e+09 -4.2949673e+09]\n",
            "  [-4.2949673e+09 -4.2949673e+09]]\n",
            "\n",
            " [[-4.2949673e+09 -4.2949673e+09]\n",
            "  [-4.2949673e+09 -4.2949673e+09]]\n",
            "\n",
            " [[-4.2949673e+09 -4.2949673e+09]\n",
            "  [-4.2949673e+09 -4.2949673e+09]]\n",
            "\n",
            " [[-4.2949673e+09 -4.2949673e+09]\n",
            "  [-4.2949673e+09 -4.2949673e+09]]\n",
            "\n",
            " [[-4.2949673e+09 -4.2949673e+09]\n",
            "  [-4.2949673e+09 -4.2949673e+09]]\n",
            "\n",
            " [[-4.2949673e+09 -4.2949673e+09]\n",
            "  [-4.2949673e+09 -4.2949673e+09]]\n",
            "\n",
            " [[-4.2949673e+09 -4.2949673e+09]\n",
            "  [-4.2949673e+09 -4.2949673e+09]]\n",
            "\n",
            " [[-4.2949673e+09 -4.2949673e+09]\n",
            "  [-4.2949673e+09 -4.2949673e+09]]\n",
            "\n",
            " [[-4.2949673e+09 -4.2949673e+09]\n",
            "  [-4.2949673e+09 -4.2949673e+09]]\n",
            "\n",
            " [[-4.2949673e+09 -4.2949673e+09]\n",
            "  [-4.2949673e+09 -4.2949673e+09]]]\n",
            "outputs is [[[ 1.8275585e-02 -4.2949673e+09]\n",
            "  [-7.3261574e-02  1.9629422e+00]]\n",
            "\n",
            " [[ 1.9506203e-01 -4.2949673e+09]\n",
            "  [-5.7942790e-01  1.9629422e+00]]\n",
            "\n",
            " [[ 1.6063472e+00 -4.2949673e+09]\n",
            "  [-4.2949673e+09 -4.2949673e+09]]\n",
            "\n",
            " [[ 6.9303334e-02 -4.2949673e+09]\n",
            "  [ 7.9884380e-02  1.8658684e+00]]\n",
            "\n",
            " [[ 2.8750312e-01 -4.2949673e+09]\n",
            "  [-7.1892834e-01  1.8658684e+00]]\n",
            "\n",
            " [[ 2.6580191e+00 -4.2949673e+09]\n",
            "  [-4.2949673e+09 -4.2949673e+09]]\n",
            "\n",
            " [[ 7.5959280e-02 -4.2949673e+09]\n",
            "  [ 2.5639975e-01  2.4419007e+00]]\n",
            "\n",
            " [[ 8.4300704e-02 -4.2949673e+09]\n",
            "  [-3.9248741e-01  2.4419007e+00]]\n",
            "\n",
            " [[ 1.4407275e+00 -4.2949673e+09]\n",
            "  [-4.2949673e+09 -4.2949673e+09]]\n",
            "\n",
            " [[ 1.1954813e-03 -4.2949673e+09]\n",
            "  [ 8.4217079e-02  1.9230998e+00]]\n",
            "\n",
            " [[ 2.4081707e-01 -4.2949673e+09]\n",
            "  [-3.9091215e-01  1.9230998e+00]]\n",
            "\n",
            " [[ 1.9546721e+00 -4.2949673e+09]\n",
            "  [-4.2949673e+09 -4.2949673e+09]]]\n",
            "outputs is [[[1.         0.        ]\n",
            "  [0.11545385 0.8845462 ]]\n",
            "\n",
            " [[1.         0.        ]\n",
            "  [0.07294075 0.9270593 ]]\n",
            "\n",
            " [[1.         0.        ]\n",
            "  [0.5        0.5       ]]\n",
            "\n",
            " [[1.         0.        ]\n",
            "  [0.1435658  0.8564342 ]]\n",
            "\n",
            " [[1.         0.        ]\n",
            "  [0.0701233  0.9298767 ]]\n",
            "\n",
            " [[1.         0.        ]\n",
            "  [0.5        0.5       ]]\n",
            "\n",
            " [[1.         0.        ]\n",
            "  [0.10106007 0.8989399 ]]\n",
            "\n",
            " [[1.         0.        ]\n",
            "  [0.05549394 0.94450605]]\n",
            "\n",
            " [[1.         0.        ]\n",
            "  [0.5        0.5       ]]\n",
            "\n",
            " [[1.         0.        ]\n",
            "  [0.1371835  0.8628166 ]]\n",
            "\n",
            " [[1.         0.        ]\n",
            "  [0.08996914 0.91003084]]\n",
            "\n",
            " [[1.         0.        ]\n",
            "  [0.5        0.5       ]]]\n",
            "outputs is [[[-0.35401535  0.16785428 -0.2806974   0.20122606  0.19805932\n",
            "    0.00520189  0.40723792  0.19045086 -0.4242846  -0.3921116\n",
            "   -0.12833405  0.05190503  0.13954674 -0.20217767  0.0241056\n",
            "   -0.14260417]\n",
            "  [ 0.5985264   0.61452883  0.46752572  0.5033788   0.82314\n",
            "    0.78675026  0.8059198   0.6976361   0.62428     0.448689\n",
            "    0.5035059   0.5530674   0.6848478   0.7454112   0.5891522\n",
            "    0.707627  ]]\n",
            "\n",
            " [[-0.5714387  -0.31164894 -0.3147472  -0.58699644 -0.10410819\n",
            "    0.11590059 -0.22390892 -0.30920675 -0.22965458 -0.20493264\n",
            "   -0.135294   -0.49745262 -0.04054511 -0.17120321 -0.01237173\n",
            "   -0.0559508 ]\n",
            "  [ 0.6284485   0.6010216   0.5010032   0.46040735  0.8311423\n",
            "    0.8323875   0.7790449   0.6855671   0.6888725   0.50275254\n",
            "    0.5333657   0.5370837   0.69792     0.79321355  0.61364883\n",
            "    0.75481135]]\n",
            "\n",
            " [[-0.67577404 -0.9966262  -1.0055227  -0.5782866  -0.5255195\n",
            "   -0.5798681  -0.33335963 -0.8765048  -0.20154138 -0.6726342\n",
            "   -0.37786302 -0.38453013 -0.5845002  -0.7012312  -0.74190897\n",
            "   -0.6536736 ]\n",
            "  [-0.30246985 -0.38689634 -0.47471723 -0.22200632 -0.1741579\n",
            "   -0.2390575  -0.04536653 -0.34387296 -0.05596402 -0.34336814\n",
            "   -0.16587886 -0.16644101 -0.21049887 -0.2387743  -0.28844476\n",
            "   -0.2641058 ]]\n",
            "\n",
            " [[ 0.30178165  0.14480674 -0.06126373  0.11364674  0.1200864\n",
            "    0.05482554  0.12106882  0.2080185   0.11655731 -0.29836935\n",
            "    0.53302276  0.11785416  0.09502711  0.08009644  0.3611247\n",
            "   -0.1473192 ]\n",
            "  [ 0.57769465  0.5319561   0.5726838   0.64390117  0.76906747\n",
            "    0.87512     0.9254381   0.6696018   0.5742713   0.58952105\n",
            "    0.69978714  0.7602847   0.41139174  0.6195421   0.5095825\n",
            "    0.38858217]]\n",
            "\n",
            " [[-0.29095647 -0.40897852 -0.22209367 -0.222539   -0.38037488\n",
            "    0.0056466  -0.11871795 -0.17068784  0.1973876  -0.13506502\n",
            "    0.1244864  -0.06180981 -0.35448942 -0.12095905 -0.27484116\n",
            "   -0.03807668]\n",
            "  [ 0.5597905   0.5263223   0.61576927  0.66579807  0.789626\n",
            "    0.94201475  0.9776012   0.68262815  0.6191901   0.67711246\n",
            "    0.6854398   0.8027769   0.4069996   0.65170294  0.47771728\n",
            "    0.4421982 ]]\n",
            "\n",
            " [[-0.41524273 -0.5449059  -1.1473305  -0.24227312 -0.48790255\n",
            "   -0.8188043  -0.7026203  -0.8145386  -0.66173875 -0.55077815\n",
            "   -0.63536614 -0.39707974 -0.03112491 -0.39484844 -0.39905167\n",
            "   -1.239323  ]\n",
            "  [-0.12946075 -0.16319013 -0.550356   -0.09357629 -0.13783962\n",
            "   -0.3451725  -0.2276715  -0.26580346 -0.2629527  -0.22570512\n",
            "   -0.2334247  -0.0848194   0.05580167 -0.12282151 -0.14048256\n",
            "   -0.5609991 ]]\n",
            "\n",
            " [[-0.10356595  0.49102888  0.13692959 -0.39652747  0.09446822\n",
            "    0.18068554  0.2420315  -0.05215393 -0.31290945  0.30645084\n",
            "    0.08860928 -0.1908356  -0.17008515  0.08096126 -0.18258165\n",
            "    0.0202966 ]\n",
            "  [ 0.4511056   0.6009765   0.6906008   0.6735808   1.0584602\n",
            "    0.7129383   0.9948934   1.13109     0.56404436  0.39708963\n",
            "    0.6488179   0.27916914  0.4981979   0.62628216  0.73577386\n",
            "    0.77523273]]\n",
            "\n",
            " [[-0.01633055 -0.05876606  0.3719644  -0.60450417 -0.5335016\n",
            "   -0.23891027 -0.09803993 -0.16575815 -0.01490546 -0.1631088\n",
            "   -0.47295684 -0.33007345  0.02502525  0.01028723 -0.5590626\n",
            "   -0.27533162]\n",
            "  [ 0.48406222  0.5760393   0.7317087   0.71628183  1.0724753\n",
            "    0.71663254  1.0141832   1.1847628   0.6250335   0.37562627\n",
            "    0.6460507   0.29526624  0.5428998   0.6500018   0.76143175\n",
            "    0.7970939 ]]\n",
            "\n",
            " [[-0.28019163 -0.82501894 -0.39284083 -0.54804415 -0.67276627\n",
            "   -0.41869217 -0.87998915 -0.6157794  -0.7016717  -0.4253043\n",
            "   -0.67947465 -0.7166253  -0.596645   -1.0672265  -0.71168\n",
            "   -0.5306417 ]\n",
            "  [-0.04059967 -0.34327447 -0.07277942 -0.20869663 -0.25564942\n",
            "   -0.08325559 -0.3822831  -0.27731436 -0.2882925  -0.16515985\n",
            "   -0.3031274  -0.29366785 -0.22000524 -0.46515197 -0.25539458\n",
            "   -0.10564458]]\n",
            "\n",
            " [[-0.10308849 -0.46980903  0.18761896 -0.23427093  0.6052053\n",
            "    0.6960433   0.33303782 -0.34123     0.2038977   0.37747672\n",
            "   -0.10450746  0.1532807   0.03708097  0.11657559 -0.05165692\n",
            "   -0.18063869]\n",
            "  [ 0.88025755  0.720634    0.63233125  0.6306691   1.034802\n",
            "    0.5291692   0.56565183  0.71826464  0.65994686  0.6463803\n",
            "    0.602012    0.4152322   0.90394455  0.7735581   0.39767393\n",
            "    0.8513279 ]]\n",
            "\n",
            " [[-0.32314017 -0.27593744 -0.41664425 -0.2136427  -0.1543453\n",
            "   -0.49106854  0.03055143 -0.5051001   0.01708066  0.02053983\n",
            "   -0.16335589 -0.07458442 -0.10120325 -0.5918402  -0.26291916\n",
            "   -0.34178686]\n",
            "  [ 0.91426945  0.80321884  0.60230136  0.6798555   0.9899738\n",
            "    0.41323417  0.55116624  0.76149815  0.6680946   0.6289817\n",
            "    0.63537896  0.40906563  0.938939    0.7457733   0.40325475\n",
            "    0.8932999 ]]\n",
            "\n",
            " [[-0.7696475  -0.47205797 -0.77811867 -0.3705885  -0.6869924\n",
            "   -0.7661864  -0.8126204  -0.6843079  -0.5039565  -0.89466023\n",
            "   -0.70908767 -0.5284408  -0.24351744 -0.9230337  -0.97309124\n",
            "   -0.62862533]\n",
            "  [-0.31680968 -0.15506083 -0.36385143 -0.11562431 -0.27521464\n",
            "   -0.28224647 -0.34515372 -0.28564286 -0.182099   -0.3462118\n",
            "   -0.31318343 -0.18650326 -0.02256382 -0.36137652 -0.4250091\n",
            "   -0.268519  ]]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([12,  2, 16], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17ghzmtB776u"
      },
      "source": [
        "### 3.4恢复原始序列emb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5M3W0n178ba",
        "outputId": "b82ccbdc-d404-42a6-db7a-4f6296bc0d62"
      },
      "source": [
        "mha_outputs = tf.concat(tf.split(outputs, num_heads, axis=0), axis=2)  # (N, seq_len, d_model)\n",
        "tf.shape(mha_outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 3,  2, 64], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA-7PIrh8q59"
      },
      "source": [
        "## 4.Dropout与LayerNorm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZlpQ8fh8bc7"
      },
      "source": [
        "dropout_1 = Dropout(0.01)\n",
        "dropout_2 = Dropout(0.02)\n",
        "layer_norm_1 = LayerNormalization(epsilon=1e-6, trainable=True)\n",
        "layer_norm_2 = LayerNormalization(epsilon=1e-6, trainable=True)\n",
        "# FFN\n",
        "ffn = Dense(units=emb_dims, activation='relu', use_bias=True, kernel_initializer=tf.keras.initializers.VarianceScaling(distribution='uniform'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUszTvH09vXP",
        "outputId": "8eeb2654-184b-40d4-d900-452cce8d53c7"
      },
      "source": [
        "dropout_1_out = dropout_1(mha_outputs)\n",
        "layer_norm_1_out = layer_norm_1(x + dropout_1_out)\n",
        "ffn_out = ffn(layer_norm_1_out)\n",
        "\n",
        "drouput_2_out = dropout_2(ffn_out)\n",
        "trm_out = layer_norm_2(drouput_2_out + layer_norm_1_out)\n",
        "tf.shape(trm_out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 3,  2, 64], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULeGfKgUEzqp"
      },
      "source": [
        "## 5.取待预测向量\n",
        "\n",
        "原生SASRec用于召回，这里有改动：后面操作很自由，可以变换为类似bst，用于排序；也可以用于原生SASRec实现召回."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0E8JPHc_Wsj",
        "outputId": "9d0b969f-d670-4340-eda2-b9ea681ea545"
      },
      "source": [
        "trm_out[:,-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 64), dtype=float32, numpy=\n",
              "array([[-1.84379369e-01, -9.45800185e-01, -2.22851932e-02,\n",
              "        -8.38192582e-01,  9.56860602e-01,  3.14615428e-01,\n",
              "         7.33368933e-01, -4.57641661e-01, -2.87721753e-02,\n",
              "        -1.66162729e+00, -3.33662450e-01,  6.51713789e-01,\n",
              "        -2.27731556e-01,  1.04329467e+00,  6.65294230e-01,\n",
              "         5.56918323e-01, -7.19381154e-01, -9.85158741e-01,\n",
              "        -3.48450541e-01,  1.16099119e-02,  8.54185045e-01,\n",
              "         1.98537827e+00,  5.62301576e-01,  1.17580986e+00,\n",
              "        -8.53503704e-01, -5.00624835e-01, -5.60072839e-01,\n",
              "         9.97676253e-02, -9.24546361e-01,  7.36404955e-01,\n",
              "        -5.75597525e-01, -1.00922728e+00, -2.32741570e+00,\n",
              "        -7.83360243e-01,  1.39773190e-01, -1.43922091e-01,\n",
              "         2.26295710e+00,  3.37453485e-02,  2.00631928e+00,\n",
              "         1.76497293e+00, -1.69512177e+00, -1.60295320e+00,\n",
              "        -4.00020689e-01, -1.33954775e+00,  8.61033797e-03,\n",
              "         3.13110828e-01,  4.96499836e-01, -2.39545435e-01,\n",
              "         1.37460065e+00,  8.04171145e-01,  2.53140032e-01,\n",
              "        -5.20861208e-01,  7.62056410e-01,  1.94260073e+00,\n",
              "        -5.93270123e-01, -1.91149116e-01,  1.74854040e-01,\n",
              "        -3.65087181e-01,  6.02062345e-02, -1.63300896e+00,\n",
              "         1.06084466e+00,  1.11806583e+00, -2.09651423e+00,\n",
              "         1.84382558e-01],\n",
              "       [-1.22073263e-01, -1.11047864e+00,  1.39033258e-01,\n",
              "        -9.67897356e-01,  8.23504210e-01,  2.24552810e-01,\n",
              "         5.05726159e-01, -6.15803123e-01,  1.01177931e-01,\n",
              "        -1.51102364e+00, -4.86672223e-02,  3.32967162e-01,\n",
              "        -2.68775642e-01,  1.25607586e+00,  1.05276477e+00,\n",
              "         7.98469663e-01, -8.33369732e-01, -1.11311674e+00,\n",
              "        -1.59691572e-02,  1.16129518e-02,  1.09461129e+00,\n",
              "         2.08701086e+00,  7.03189731e-01,  8.12575579e-01,\n",
              "        -6.49888277e-01, -1.09914273e-01, -7.28815854e-01,\n",
              "         1.95749223e-01, -9.53747272e-01,  7.94549465e-01,\n",
              "        -9.19223368e-01, -8.07206571e-01, -2.27495384e+00,\n",
              "        -1.00138605e+00,  2.29286075e-01, -4.68730628e-02,\n",
              "         2.38778543e+00, -5.11185229e-02,  1.99340117e+00,\n",
              "         1.76822865e+00, -1.51221907e+00, -1.85182035e+00,\n",
              "        -4.41805184e-01, -1.37068415e+00,  1.19006932e-01,\n",
              "         4.34477270e-01,  5.40636420e-01, -2.39612281e-01,\n",
              "         1.14973807e+00,  1.08678913e+00, -2.79204547e-02,\n",
              "        -3.93432856e-01,  4.50707018e-01,  1.39835238e+00,\n",
              "        -7.62645125e-01,  1.40561938e-01,  1.21190429e-01,\n",
              "        -5.48129797e-01,  1.13662601e-01, -1.56814659e+00,\n",
              "         8.46665502e-01,  8.19805503e-01, -2.17176390e+00,\n",
              "         5.04615128e-01],\n",
              "       [-5.92500567e-01, -1.64684594e+00, -1.81630075e+00,\n",
              "        -1.41376853e-01,  7.91851878e-01,  1.88101649e-01,\n",
              "         5.90752006e-01, -9.05544341e-01,  1.26047850e+00,\n",
              "        -5.10270715e-01,  4.94640708e-01,  2.55249524e+00,\n",
              "         5.92573881e-02, -1.69654682e-01, -8.96134377e-02,\n",
              "        -2.46465325e-01,  1.41705155e-01, -5.27669489e-02,\n",
              "        -1.74608850e+00,  1.40472317e+00,  4.55106854e-01,\n",
              "        -8.34944248e-01,  2.25135112e+00, -2.54967511e-02,\n",
              "        -6.94810748e-01, -4.68749613e-01, -6.00765705e-01,\n",
              "         1.24723303e+00,  2.43335056e+00,  5.04916191e-01,\n",
              "         1.16482615e-01, -2.37690520e+00,  1.30254388e+00,\n",
              "        -5.94740152e-01,  7.98816919e-01,  4.13998485e-01,\n",
              "        -1.63175076e-01,  8.18703890e-01, -1.19331193e+00,\n",
              "        -5.06855190e-01, -5.35279334e-01,  6.02126122e-04,\n",
              "        -9.91709471e-01,  6.38342202e-02,  7.05858588e-01,\n",
              "        -1.51061809e+00, -3.56310010e-02,  9.12045240e-01,\n",
              "        -3.11357409e-01,  2.85054147e-01, -1.24972892e+00,\n",
              "         1.64788151e+00, -4.02472347e-01, -4.17495698e-01,\n",
              "        -9.52609777e-01, -4.68215525e-01,  1.46883965e+00,\n",
              "        -1.04673833e-01, -9.17111576e-01,  4.00631011e-01,\n",
              "         1.02437139e+00,  3.99874449e-01, -9.63964820e-01,\n",
              "        -4.97450948e-01]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHvRZvlEDwWi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}