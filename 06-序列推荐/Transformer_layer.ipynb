{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transformer_layer.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPcBd75bMqMnRqzyEItNViO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"UYWNFIsXGlUM"},"source":["# Transformer\n","\n","encoder结构"]},{"cell_type":"code","metadata":{"id":"yedkxUUeF9hg"},"source":["import tensorflow as tf\n","from sequence_feature_layer import SequenceFeatures\n","from tensorflow import feature_column as fc\n","from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout, Embedding, Conv1D"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bA83kh-zGis5"},"source":["## 准备工作"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4QcTgSeLGIlb","executionInfo":{"status":"ok","timestamp":1637139263279,"user_tz":-480,"elapsed":622,"user":{"displayName":"于印霄","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpVABOiHAVZoTKCbmgFadD0IEDNAgt6qrk6rQQ=s64","userId":"12984923686518792253"}},"outputId":"4b9b9f9b-a207-4bed-e5b5-d3ef587fe68e"},"source":["seq = fc.sequence_categorical_column_with_hash_bucket('seq', hash_bucket_size=10, dtype=tf.int64)\n","target = fc.sequence_categorical_column_with_hash_bucket('target', hash_bucket_size=10, dtype=tf.int64)\n","seq_col = fc.embedding_column(seq, dimension=64)\n","target_col = fc.embedding_column(target, dimension=64)\n","columns = [seq_col, target_col]\n","features={\n","  \"seq\": tf.sparse.SparseTensor(\n","      indices=[[0, 0], [0, 1], [1, 0], [1, 1], [2, 0]],\n","      values=[1100, 1101, 1102, 1101, 1103],\n","      dense_shape=[3, 2]),\n","  \"target\": tf.sparse.SparseTensor(\n","      indices=[[0, 0],[1,0],[2,0]],\n","      values=[1102,1103,1100],\n","      dense_shape=[3, 1]),\n","\n","}\n","tf.sparse.to_dense(features['seq'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n","array([[1100, 1101],\n","       [1102, 1101],\n","       [1103,    0]], dtype=int32)>"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BosBDxqsGIjF","executionInfo":{"status":"ok","timestamp":1637139266140,"user_tz":-480,"elapsed":3,"user":{"displayName":"于印霄","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpVABOiHAVZoTKCbmgFadD0IEDNAgt6qrk6rQQ=s64","userId":"12984923686518792253"}},"outputId":"d0bfc90f-c56b-4241-a68e-8baa9eb2a589"},"source":["sequence_feature_layer = SequenceFeatures(columns, name='sequence_features_input_layer')\n","sequence_inputs, sequence_lengths = sequence_feature_layer(features)\n","target_input=sequence_inputs['target_embedding']\n","target_length=sequence_lengths['target_embedding']\n","sequence_input=sequence_inputs['seq_embedding']\n","sequence_length=sequence_lengths['seq_embedding']\n","tf.shape(sequence_input),sequence_length"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 3,  2, 64], dtype=int32)>,\n"," <tf.Tensor: shape=(3,), dtype=int64, numpy=array([2, 2, 1])>)"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U-Jcnim4GOdC","executionInfo":{"status":"ok","timestamp":1637139269113,"user_tz":-480,"elapsed":4,"user":{"displayName":"于印霄","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpVABOiHAVZoTKCbmgFadD0IEDNAgt6qrk6rQQ=s64","userId":"12984923686518792253"}},"outputId":"9e29a776-f31d-4d23-fa67-da48607e72f8"},"source":["x_=tf.concat([sequence_input, target_input], axis=1)\n","x_length = sequence_length+target_length\n","tf.shape(x_)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 3,  3, 64], dtype=int32)>"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4x8pcaKLGOfj","executionInfo":{"status":"ok","timestamp":1637139271876,"user_tz":-480,"elapsed":3,"user":{"displayName":"于印霄","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpVABOiHAVZoTKCbmgFadD0IEDNAgt6qrk6rQQ=s64","userId":"12984923686518792253"}},"outputId":"b7ca9aa5-e485-4e33-cb78-7d5a927b8506"},"source":["seq_mask = tf.expand_dims(tf.where(tf.sequence_mask(sequence_length),1.0,0.0),axis=-1)\n","target_mask = tf.expand_dims(tf.where(tf.sequence_mask(target_length),1.0,0.0),axis=-1)\n","mask_ = tf.concat([seq_mask,target_mask],axis=1)\n","mask_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3, 3, 1), dtype=float32, numpy=\n","array([[[1.],\n","        [1.],\n","        [1.]],\n","\n","       [[1.],\n","        [1.],\n","        [1.]],\n","\n","       [[1.],\n","        [0.],\n","        [1.]]], dtype=float32)>"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"b1nJOIfDGQZD"},"source":["## Layer搭建"]},{"cell_type":"markdown","metadata":{"id":"Dy_Fz-17G62w"},"source":["### multi_head_attention"]},{"cell_type":"code","metadata":{"id":"LWx7b5Z4GBEs"},"source":["def scaled_dot_product_attention(q, k, v, mask, causality=True):\n","    \"\"\"\n","    Attention Mechanism\n","    :param q: A 3d tensor with shape of (None, seq_len, depth), depth = d_model // num_heads\n","    :param k: A 3d tensor with shape of (None, seq_len, depth)\n","    :param v: A 3d tensor with shape of (None, seq_len, depth)\n","    :param mask:\n","    :param causality: Boolean. If True, using causality, default True\n","    :return:\n","    \"\"\"\n","    mat_qk = tf.matmul(q, k, transpose_b=True)  # (None, seq_len, seq_len)\n","    dk = tf.cast(k.shape[-1], dtype=tf.float32)\n","    # Scaled\n","    scaled_att_logits = mat_qk / tf.sqrt(dk)\n","\n","    paddings = tf.ones_like(scaled_att_logits) * (-2 ** 32 + 1)\n","    outputs = tf.where(tf.equal(mask, 0), paddings, scaled_att_logits)  # (None, seq_len, seq_len)\n","    # Causality\n","    if causality:\n","        diag_vals = tf.ones_like(outputs)  # (None, seq_len, seq_len)\n","        masks = tf.linalg.LinearOperatorLowerTriangular(diag_vals).to_dense()  # (None, seq_len, seq_len)\n","        paddings = tf.ones_like(masks) * (-2 ** 32 + 1)\n","        outputs = tf.where(tf.equal(masks, 0), paddings, outputs)  # (None, seq_len, seq_len)\n","\n","    # softmax\n","    outputs = tf.nn.softmax(logits=outputs)  # , axis=-1)  # (None, seq_len, seq_len)\n","    outputs = tf.matmul(outputs, v)  # (None, seq_len, depth)\n","\n","    return outputs\n","\n","\n","class EncoderLayer(Layer):\n","    def __init__(self, num_heads=None, att_hidden=None, embedding_size=None, ffn_dims=None, dropout=None, norm_training=None, causality=None,\n","                 **kwargs):\n","        self.num_heads = num_heads\n","        self.att_hidden = att_hidden\n","        self.embedding_size = embedding_size\n","        self.ffn_dims = ffn_dims\n","        self.dropout = dropout\n","        self.norm_training = norm_training\n","        self.causality = causality\n","\n","        self.wq = Dense(self.att_hidden, activation=None, use_bias=False,\n","                        kernel_initializer=tf.keras.initializers.VarianceScaling(distribution='uniform'), name='wq')\n","        self.wk = Dense(self.att_hidden, activation=None, use_bias=False,\n","                        kernel_initializer=tf.keras.initializers.VarianceScaling(distribution='uniform'), name='wk')\n","        self.wv = Dense(self.att_hidden, activation=None, use_bias=False,\n","                        kernel_initializer=tf.keras.initializers.VarianceScaling(distribution='uniform'), name='wv')\n","\n","        # drp and ln\n","        self.dropout_1 = Dropout(self.dropout, trainable=True)\n","        self.dropout_2 = Dropout(self.dropout, trainable=True)\n","        self.layer_norm_1 = LayerNormalization(epsilon=1e-6, trainable=self.norm_training)\n","        self.layer_norm_2 = LayerNormalization(epsilon=1e-6, trainable=self.norm_training)\n","        # FFN\n","        self.ffn = Dense(units=self.ffn_dims, activation='relu', use_bias=True,\n","                         kernel_initializer=tf.keras.initializers.VarianceScaling(distribution='uniform'))\n","\n","        super().__init__(**kwargs)\n","\n","    def call(self, inputs, *args, **kwargs):\n","        x, mask_ = inputs\n","        q_ = self.wq(x)\n","        k_ = self.wk(x)\n","        v_ = self.wv(x)\n","\n","        q = self._process_multi_head(q_)\n","        k = self._process_multi_head(k_)\n","        v = self._process_multi_head(v_)\n","\n","        mask_ = tf.tile(mask_, multiples=[1, 1, self.num_heads])\n","        mask = self._process_multi_head(mask_)\n","\n","        att_output = scaled_dot_product_attention(q, k, v, mask)\n","        mha_outputs = tf.concat(tf.split(att_output, self.num_heads, axis=0), axis=2)  # (N, seq_len, d_model)\n","\n","        dropout_1_out = self.dropout_1(mha_outputs)\n","        layer_norm_1_out = self.layer_norm_1(x + dropout_1_out)\n","        ffn_out = self.ffn(mha_outputs)\n","\n","        drouput_2_out = self.dropout_2(ffn_out)\n","        trm_out = self.layer_norm_2(drouput_2_out + layer_norm_1_out)\n","\n","        return trm_out\n","\n","    def _process_multi_head(self, emb):\n","        emb_split = tf.split(emb, self.num_heads, axis=2)\n","        emb = tf.concat(emb_split, axis=0)\n","        return emb\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"18jxoRGrG2Zo"},"source":["### Trm Layer"]},{"cell_type":"code","metadata":{"id":"vje4Aet6GBHH"},"source":["class Transformer(Layer):\n","    def __init__(self, num_blocks=3, num_heads=4, seq_len=100, att_hidden=64, embedding_size=64, ffn_dims=64, dropout=0.05, norm_training=True,\n","                 causality=False,\n","                 **kwargs):\n","        self.num_blocks = num_blocks\n","        self.num_heads = num_heads\n","        self.att_hidden = att_hidden\n","        self.embedding_size = embedding_size\n","        self.ffn_dims = ffn_dims\n","        self.seq_len = seq_len\n","        self.dropout = dropout\n","        self.norm_training = norm_training\n","        self.causality = causality\n","\n","        # pos_emb\n","        self.pos_encoding = Embedding(\n","            input_dim=self.seq_len,\n","            output_dim=self.embedding_size,\n","            name=\"position_embedding\")\n","\n","        # dropout\n","        self.dropout_layer = Dropout(self.dropout)\n","\n","        # blocks\n","        self.encoder_layer = [EncoderLayer(self.num_heads, self.att_hidden, self.embedding_size, self.ffn_dims,\n","                                           self.dropout, self.norm_training, self.causality) for i in range(self.num_blocks)]\n","\n","        super().__init__(**kwargs)\n","\n","    def call(self, inputs, *args, **kwargs):\n","        x_, mask_ = inputs\n","\n","        positions = tf.range(start=0, limit=tf.shape(x_)[1], delta=1)\n","        x = x_ + tf.expand_dims(self.pos_encoding(positions), 0)\n","        net = self.dropout_layer(x)\n","\n","        for index, encoder in enumerate(self.encoder_layer):\n","            print('index_{}_encoder_{}_net_{}'.format(index, encoder, tf.shape(net)))\n","            net = encoder([net, mask_])\n","            net *= mask_\n","            print('after mask net is '.format(net))\n","\n","        return net\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LyfIH_2KG9Ku"},"source":["## 执行"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6aM5k1jOGBLx","executionInfo":{"status":"ok","timestamp":1637139396010,"user_tz":-480,"elapsed":4,"user":{"displayName":"于印霄","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpVABOiHAVZoTKCbmgFadD0IEDNAgt6qrk6rQQ=s64","userId":"12984923686518792253"}},"outputId":"e8c9247a-a53a-45de-df99-1909c65bfa24"},"source":["trm_layer = Transformer()\n","trm_layer"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<__main__.Transformer at 0x7fb81e064290>"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SPw6IDlzGBOQ","executionInfo":{"status":"ok","timestamp":1637139411962,"user_tz":-480,"elapsed":830,"user":{"displayName":"于印霄","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpVABOiHAVZoTKCbmgFadD0IEDNAgt6qrk6rQQ=s64","userId":"12984923686518792253"}},"outputId":"e0c172e0-1f7d-4153-ba76-d4f43a6e09b4"},"source":["output = trm_layer([x_, mask_])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["index_0_encoder_<__main__.EncoderLayer object at 0x7fb81e064810>_net_[ 3  3 64]\n","after mask net is \n","index_1_encoder_<__main__.EncoderLayer object at 0x7fb81e0062d0>_net_[ 3  3 64]\n","after mask net is \n","index_2_encoder_<__main__.EncoderLayer object at 0x7fb81e001950>_net_[ 3  3 64]\n","after mask net is \n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gq9nHj0AGBzT","executionInfo":{"status":"ok","timestamp":1637139419435,"user_tz":-480,"elapsed":4,"user":{"displayName":"于印霄","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpVABOiHAVZoTKCbmgFadD0IEDNAgt6qrk6rQQ=s64","userId":"12984923686518792253"}},"outputId":"27c9bd16-eaed-4ad4-e863-90baa27f2eef"},"source":["output[:,-1]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3, 64), dtype=float32, numpy=\n","array([[ 2.9326947 ,  0.69362676,  0.9936812 , -0.8257617 ,  0.08538669,\n","         0.23545605,  1.29105   ,  0.11086974, -0.8754775 , -0.5112791 ,\n","        -1.2423049 , -0.45985162, -0.6020464 ,  1.4475819 ,  0.62697715,\n","        -0.16384442,  0.5519566 , -0.86469024,  0.8320564 , -0.8523632 ,\n","        -0.14820299,  1.12581   , -1.3312322 ,  2.5265052 ,  0.2369073 ,\n","         0.6300299 , -1.277069  , -0.6257964 , -1.0155196 , -0.29722834,\n","        -0.09147831,  0.13335192,  0.8710997 , -0.12049151,  0.5275751 ,\n","         0.10439041,  0.31844503, -1.0451658 , -0.7986394 , -0.50971556,\n","         2.2151523 , -0.6969824 ,  0.6148121 ,  0.6670119 , -1.1124527 ,\n","        -0.39789087,  1.4995996 ,  0.04672161,  0.6685069 , -1.529521  ,\n","        -0.1502356 , -0.1818445 , -1.1916966 , -0.05184604, -1.0963775 ,\n","         1.4292254 , -0.4543887 ,  0.7681211 , -0.87967885, -0.49879047,\n","        -1.9696634 ,  0.25545433, -1.6738725 ,  1.1033427 ],\n","       [ 1.9888783 , -0.17362092, -0.12375669, -0.8791593 , -0.81503314,\n","        -1.2956853 , -1.6263735 ,  0.4252686 ,  0.7241299 , -0.9486176 ,\n","        -0.7007716 , -0.42971176,  0.6195223 , -1.0182977 ,  0.34955335,\n","         0.8260977 , -1.2751462 , -0.40233546,  0.35928804, -1.3154202 ,\n","        -0.7147064 ,  0.5327631 ,  0.3560874 , -0.44312772,  0.43172455,\n","        -0.24971867, -1.9234028 ,  2.7049646 ,  0.22800756, -0.66627413,\n","        -0.53938156,  1.4809909 , -1.1281333 , -0.4413744 ,  0.04068309,\n","        -0.3127923 ,  3.1904929 ,  0.18433031,  0.49193984,  2.3020372 ,\n","         0.55219775,  1.4237182 , -1.3677732 ,  0.57983893,  0.830932  ,\n","         1.6137167 , -0.68573225,  0.87534976,  0.8190268 , -0.7074511 ,\n","         0.13325545, -0.68545794, -0.6771305 , -0.7055307 , -0.65642774,\n","        -0.46625313,  0.38252532, -0.06089996,  0.19368377, -0.8276718 ,\n","        -0.14480676, -0.32800928,  0.22157788, -0.1265984 ],\n","       [-1.6148126 , -0.33619386, -0.22404164,  0.68107027,  0.2361982 ,\n","         1.1498834 , -0.89830554,  0.05362839, -2.372444  , -0.9026047 ,\n","         0.8285401 ,  0.31544554,  0.6296215 , -3.4995174 ,  1.1498092 ,\n","         0.6865372 ,  1.1028577 , -0.0804209 , -0.25245696, -0.76433825,\n","        -0.7725575 , -0.6129811 , -1.1374376 , -1.5770682 ,  1.4247075 ,\n","        -0.6722545 , -1.1347269 ,  1.2264789 , -1.6373919 ,  0.6632025 ,\n","        -1.3080403 , -0.14409366,  0.42336452, -0.09767987,  0.52163994,\n","         2.3049097 ,  0.7437775 ,  0.9779508 , -0.10550119,  0.41515374,\n","         1.212612  ,  0.3077184 ,  0.62953645,  0.08398218,  1.0500736 ,\n","         0.50901365,  0.15828161, -0.33858317,  0.07372291,  1.2267046 ,\n","         0.7290808 , -0.6176698 ,  0.07772158, -0.8139152 , -1.5777838 ,\n","        -0.23806444,  0.5650089 ,  0.9716512 , -0.42040282,  0.569131  ,\n","         0.25059736,  0.2839653 ,  0.8743286 , -0.9566184 ]],\n","      dtype=float32)>"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"xC-SMaqbGB1h"},"source":[""],"execution_count":null,"outputs":[]}]}