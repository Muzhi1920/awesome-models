{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muzhi1920/awesome-models/blob/main/09-Estimator/00_Wide%26Deep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "30d7a11c-8e9c-4e19-ac56-4c6e7fe74917",
      "metadata": {
        "id": "30d7a11c-8e9c-4e19-ac56-4c6e7fe74917"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "os.environ['TF_CONFIG'] = '{\"task\":{\"type\":\"worker\",\"index\":0}}' #单机演示"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2428863-1082-4cc6-a571-b4b193a26b8c",
      "metadata": {
        "id": "d2428863-1082-4cc6-a571-b4b193a26b8c"
      },
      "source": [
        "## Datasets读取与解析pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "414a3f22-758f-49c2-a111-c717eb9e4762",
      "metadata": {
        "id": "414a3f22-758f-49c2-a111-c717eb9e4762"
      },
      "source": [
        "### 1. 定义特征proto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "655a2825-e5dc-4410-aeb8-b06f464884c3",
      "metadata": {
        "id": "655a2825-e5dc-4410-aeb8-b06f464884c3"
      },
      "outputs": [],
      "source": [
        "feature_proto = {\n",
        "    'sparse_000': tf.io.VarLenFeature(tf.int64),\n",
        "    'sparse_001': tf.io.VarLenFeature(tf.int64),\n",
        "    'sparse_002': tf.io.VarLenFeature(tf.int64),\n",
        "    'dense_000': tf.io.FixedLenFeature((), tf.int64, 0),\n",
        "    'dense_001': tf.io.FixedLenFeature((), tf.float32, 0.0), #label ,need pop\n",
        "    'dense_002': tf.io.FixedLenFeature((), tf.float32, 0.0),\n",
        "    'dense_003': tf.io.FixedLenFeature((), tf.float32, 0.0)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22d7d766",
      "metadata": {
        "id": "22d7d766"
      },
      "source": [
        "### 2. 实现datasets消费与解析"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7a5521b3-554f-4836-bad0-444077688674",
      "metadata": {
        "id": "7a5521b3-554f-4836-bad0-444077688674"
      },
      "outputs": [],
      "source": [
        "def parse_example_batch(example, feature_proto):\n",
        "    '''\n",
        "     - serialized: A vector (1-D Tensor) of strings, a batch of binary serialized `Example` protos.\n",
        "     - features: A `dict` mapping feature keys to `FixedLenFeature`, `VarLenFeature`, `SparseFeature`, and `RaggedFeature` values.\n",
        "    '''\n",
        "    features = tf.io.parse_example(example, feature_proto) #dict\n",
        "    label_shape = tf.shape(features['dense_001'])\n",
        "\n",
        "    label_dict = dict()\n",
        "    pos_label = tf.fill(dims=label_shape, value=tf.constant(1.0, tf.float32))\n",
        "    neg_label = tf.fill(dims=label_shape, value=tf.constant(0.0, tf.float32))\n",
        "    label_dict['ctr'] = tf.where(tf.greater(features['dense_001'], 0.0), pos_label, neg_label)\n",
        "    return features, label_dict\n",
        "\n",
        "def _tfrecord_input_fn(data_path, batch_size, epochs, feature_proto, num_shards, index):\n",
        "    tf_files = tf.io.match_filenames_once(data_path)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(tf_files).shard(num_shards, index).shuffle(10, reshuffle_each_iteration=True).interleave(\n",
        "        lambda _file: tf.data.TFRecordDataset(_file),\n",
        "        cycle_length=2,\n",
        "        block_length=8,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE).shuffle(batch_size * 20, reshuffle_each_iteration=True).repeat(epochs).batch(batch_size)\n",
        "    prefetch_dataset = dataset.map(lambda example: parse_example_batch(example, feature_proto), num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "    return prefetch_dataset\n",
        "\n",
        "def _input_fn(data_path, feature_proto):\n",
        "    return lambda: _tfrecord_input_fn(data_path=data_path, batch_size=4, epochs=20, feature_proto=feature_proto, num_shards=1, index=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c9bdec77-8c25-41d1-9dc8-18ded734571c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9bdec77-8c25-41d1-9dc8-18ded734571c",
        "outputId": "79b09cb0-105f-4277-ea96-8b1f4adcc636"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=({'sparse_000': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'sparse_001': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'sparse_002': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'dense_000': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'dense_001': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'dense_002': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'dense_003': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}, {'ctr': TensorSpec(shape=(None,), dtype=tf.float32, name=None)})>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "ds = _tfrecord_input_fn('./data/simple.tfrecord', 4, 20, feature_proto, 1, 0)\n",
        "ds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42266c61",
      "metadata": {
        "id": "42266c61"
      },
      "source": [
        "### 查看dataset数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "91c57a7c-22e8-467a-8214-13ae799e5408",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91c57a7c-22e8-467a-8214-13ae799e5408",
        "outputId": "f7adcf52-1774-491e-f0b4-cadc99350faa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7f6c9c97dcd0>,\n",
              " <tf.Tensor: shape=(4, 25), dtype=int64, numpy=\n",
              " array([[                  0,                   0,                   0,\n",
              "                           0,                   0,                   0,\n",
              "                           0,                   0,                   0,\n",
              "                           0,                   0,                   0,\n",
              "                           0,                   0,                   0,\n",
              "                           0,                   0,                   0,\n",
              "                           0,                   0,                   0,\n",
              "                           0,                   0,                   0,\n",
              "                           0],\n",
              "        [ 168392281970674538, 1044814902578433622, 1388551246485349775,\n",
              "                           0,                   0,                   0,\n",
              "                           0,                   0,                   0,\n",
              "                           0,                   0,                   0,\n",
              "                           0,                   0,                   0,\n",
              "                           0,                   0,                   0,\n",
              "                           0,                   0,                   0,\n",
              "                           0,                   0,                   0,\n",
              "                           0],\n",
              "        [3938493606363199875,  940005820428966936, 1388551246485349775,\n",
              "         3176456358074856675, 1839966314578937026, 1546258274562523655,\n",
              "         1578852913272866966,  168392281970674538, 2852617023009443359,\n",
              "         1225259752974231577, 1782549728060643733, 3705579945323836710,\n",
              "         2518151127894641914, 1044814902578433622, 1214093769154996398,\n",
              "         3770820514280335645, 1682102410434758720, 1413121672890215559,\n",
              "          166856313775117084,  120643703970840193, 1623084063230660018,\n",
              "          235886211980916503,  608315739068893201, 4567548547973033170,\n",
              "         2282275905148550114],\n",
              "        [1388551246485349775, 2852617023009443359, 1682102410434758720,\n",
              "          168392281970674538, 2518151127894641914, 1546258274562523655,\n",
              "         3176456358074856675,  120643703970840193, 1225259752974231577,\n",
              "         4567548547973033170, 1782549728060643733,                   0,\n",
              "                           0,                   0,                   0,\n",
              "                           0,                   0,                   0,\n",
              "                           0,                   0,                   0,\n",
              "                           0,                   0,                   0,\n",
              "                           0]])>,\n",
              " {'ctr': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 1., 1., 0.], dtype=float32)>})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "iter = tf.compat.v1.data.make_one_shot_iterator(ds)\n",
        "features, labels = iter.get_next()\n",
        "features['sparse_000'], tf.sparse.to_dense(features['sparse_000']), labels,"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c956ed7e-13d7-4fd9-bf12-891d4c5d9dc4",
      "metadata": {
        "id": "c956ed7e-13d7-4fd9-bf12-891d4c5d9dc4"
      },
      "source": [
        "## Feature Column实现特征处理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ff5ff3fa-a37d-4c4d-80ec-af266804603b",
      "metadata": {
        "id": "ff5ff3fa-a37d-4c4d-80ec-af266804603b"
      },
      "outputs": [],
      "source": [
        "from tensorflow import feature_column as fc\n",
        "def build_columns(feature_proto):\n",
        "    wide_columns = []\n",
        "    deep_columns = []\n",
        "    for feature, _ in feature_proto.items():\n",
        "        if 'sparse' in feature:\n",
        "            hash_bkt_input = fc.categorical_column_with_hash_bucket(feature, 64, tf.int64)\n",
        "            emb_input = fc.embedding_column(hash_bkt_input, 8, 'sqrtn', tf.keras.initializers.VarianceScaling(distribution='uniform'))\n",
        "            wide_columns.append(hash_bkt_input)\n",
        "            deep_columns.append(emb_input)\n",
        "        elif 'dense' in feature:\n",
        "            dense_input = fc.numeric_column(feature, default_value=0.0)\n",
        "            deep_columns.append(dense_input)\n",
        "            wide_columns.append(dense_input)\n",
        "        else:\n",
        "            print('exception feature is : ',feature)\n",
        "    return wide_columns, deep_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "db40bae7-2e55-4d34-8e08-cb19c51d73d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db40bae7-2e55-4d34-8e08-cb19c51d73d8",
        "outputId": "c33235b8-7407-4655-a54f-d690d36ef224"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([HashedCategoricalColumn(key='sparse_000', hash_bucket_size=64, dtype=tf.int64),\n",
              "  HashedCategoricalColumn(key='sparse_001', hash_bucket_size=64, dtype=tf.int64),\n",
              "  HashedCategoricalColumn(key='sparse_002', hash_bucket_size=64, dtype=tf.int64),\n",
              "  NumericColumn(key='dense_000', shape=(1,), default_value=(0.0,), dtype=tf.float32, normalizer_fn=None),\n",
              "  NumericColumn(key='dense_002', shape=(1,), default_value=(0.0,), dtype=tf.float32, normalizer_fn=None),\n",
              "  NumericColumn(key='dense_003', shape=(1,), default_value=(0.0,), dtype=tf.float32, normalizer_fn=None)],\n",
              " [EmbeddingColumn(categorical_column=HashedCategoricalColumn(key='sparse_000', hash_bucket_size=64, dtype=tf.int64), dimension=8, combiner='sqrtn', initializer=<keras.initializers.initializers_v2.VarianceScaling object at 0x7f6c9c9ee490>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True),\n",
              "  EmbeddingColumn(categorical_column=HashedCategoricalColumn(key='sparse_001', hash_bucket_size=64, dtype=tf.int64), dimension=8, combiner='sqrtn', initializer=<keras.initializers.initializers_v2.VarianceScaling object at 0x7f6c9c97de10>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True),\n",
              "  EmbeddingColumn(categorical_column=HashedCategoricalColumn(key='sparse_002', hash_bucket_size=64, dtype=tf.int64), dimension=8, combiner='sqrtn', initializer=<keras.initializers.initializers_v2.VarianceScaling object at 0x7f6c9c97d850>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True),\n",
              "  NumericColumn(key='dense_000', shape=(1,), default_value=(0.0,), dtype=tf.float32, normalizer_fn=None),\n",
              "  NumericColumn(key='dense_002', shape=(1,), default_value=(0.0,), dtype=tf.float32, normalizer_fn=None),\n",
              "  NumericColumn(key='dense_003', shape=(1,), default_value=(0.0,), dtype=tf.float32, normalizer_fn=None)])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "'''serving_input_receiver_fn that expects all features to be fed directly.'''\n",
        "serving_feature = feature_proto.copy()\n",
        "serving_feature.pop('dense_001') # feed features into model, except labes\n",
        "wide_columns, deep_columns = build_columns(serving_feature)\n",
        "wide_columns, deep_columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10c0f98c",
      "metadata": {
        "id": "10c0f98c"
      },
      "source": [
        "## 样本维度Tensor输入model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba710234-4aa9-4e3d-878f-177b30131780",
      "metadata": {
        "id": "ba710234-4aa9-4e3d-878f-177b30131780"
      },
      "source": [
        "### Wide部分"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "43f06150-b62b-47a1-b363-8b175541f221",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43f06150-b62b-47a1-b363-8b175541f221",
        "outputId": "f5ee1ab8-a39e-4413-c077-0ac4adaff587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/canned/linear.py:1478: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  getter=tf.compat.v1.get_variable)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 1), dtype=float32, numpy=\n",
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from tensorflow_estimator.python.estimator.canned.linear import _linear_model_fn_builder_v2 as wide_model\n",
        "wide_output, wide_weights = wide_model(units=1, feature_columns=wide_columns, sparse_combiner='sum', features=features)\n",
        "wide_output #, wide_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2370fbee-d44f-4169-a34b-c60113d482cd",
      "metadata": {
        "id": "2370fbee-d44f-4169-a34b-c60113d482cd"
      },
      "source": [
        "### Deep部分"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1ae0fc4f-03e9-49a6-b878-132147769c86",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ae0fc4f-03e9-49a6-b878-132147769c86",
        "outputId": "8ef68ff6-59c0-4fa4-e6a7-e52d9e15c4f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.feature_column.dense_features_v2.DenseFeatures at 0x7f6c956ecc90>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "input_layer = tf.keras.layers.DenseFeatures(feature_columns=deep_columns, name='deep_input')\n",
        "input_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "710de09e-bcbd-4287-88f1-33d6ac41f2f5",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "710de09e-bcbd-4287-88f1-33d6ac41f2f5",
        "outputId": "39f03bf5-d299-4872-9ba4-0dfecd15b185"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 27), dtype=float32, numpy=\n",
              "array([[ 0.0000000e+00,  0.0000000e+00, -8.3323002e-02,  0.0000000e+00,\n",
              "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
              "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -3.7095070e-02,\n",
              "         2.3599686e-01,  3.6472061e-01,  1.1396408e-01, -2.8706622e-01,\n",
              "        -3.0907178e-01,  1.2102008e-02, -1.8952183e-01,  0.0000000e+00,\n",
              "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
              "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
              "       [ 0.0000000e+00,  0.0000000e+00, -1.5305100e-01, -3.5761565e-02,\n",
              "        -1.4589924e-01,  1.9014908e-01, -4.0890642e-02,  1.3951302e-02,\n",
              "         5.0776634e-02,  4.8859835e-02,  6.7970626e-02, -8.5156314e-02,\n",
              "         1.2871352e-01,  2.6085344e-01, -3.9815154e-02, -2.5092021e-01,\n",
              "        -3.8565766e-02,  1.4258026e-01,  1.9833410e-01, -3.5256825e-02,\n",
              "         1.0200072e-01,  1.1975102e-02, -3.8204312e-02, -1.0419901e-01,\n",
              "        -1.6082984e-01,  9.2408992e-02,  1.8523392e-01],\n",
              "       [ 6.2835000e+04,  0.0000000e+00,  9.4100001e-04,  5.5418186e-02,\n",
              "         2.3830453e-02,  3.3186349e-01,  1.8798390e-02, -1.8176582e-02,\n",
              "        -1.1679417e-01,  1.4107774e-01, -2.0299008e-01,  1.2369472e-02,\n",
              "         8.1549615e-02,  4.9961162e-01, -1.1679096e-01, -2.7301288e-01,\n",
              "        -1.0452740e-01, -5.4194279e-02,  1.1544819e-01, -5.7078943e-02,\n",
              "         3.4103502e-02,  1.5087266e-01, -1.3660626e-01, -1.3085030e-01,\n",
              "        -9.4071746e-02,  6.5888576e-02,  1.9676839e-01],\n",
              "       [ 2.9940000e+03,  0.0000000e+00, -7.8599997e-02, -6.9167137e-02,\n",
              "        -7.2262399e-02,  2.2815332e-01,  1.0805260e-02,  7.1442418e-02,\n",
              "        -1.7343786e-01,  2.5897655e-01,  2.4109239e-02,  2.0675133e-01,\n",
              "         2.0434530e-01,  2.0692167e-01,  1.7185816e-01, -6.4856216e-02,\n",
              "        -3.9150339e-02, -1.5099348e-01, -6.4097308e-02, -1.7696597e-01,\n",
              "         2.5654316e-01,  4.5740347e-02, -1.3980967e-01, -7.9311505e-02,\n",
              "        -1.4468476e-01,  1.4868133e-01,  1.6394818e-01]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "input_layer(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bd8e0a9",
      "metadata": {
        "id": "3bd8e0a9"
      },
      "source": [
        "## 基于Estimator封装Wide&Deep模型\n",
        "\n",
        "- 重写model_fn函数，实现自定义estimator；\n",
        "- 通过各model模块得到目标输出和优化op；\n",
        "- 配置优化器得到优化loss的op"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8ca003b7-0815-4dce-bcae-62b82fb43b2f",
      "metadata": {
        "id": "8ca003b7-0815-4dce-bcae-62b82fb43b2f"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.python.keras.engine import training\n",
        "class DNN(training.Model):\n",
        "  \"\"\"A DNN Model.\"\"\"\n",
        "  def __init__(self,\n",
        "               deep_columns = None,\n",
        "               dnn_dims = [16, 8, 1],\n",
        "               name=None,\n",
        "               **kwargs):\n",
        "    super(DNN, self).__init__(name=name, **kwargs)\n",
        "    self._input_layer = tf.keras.layers.DenseFeatures(feature_columns=deep_columns, name='deep')\n",
        "    self._dnn = [Dense(dims, 'relu') for dims in dnn_dims]\n",
        "  \n",
        "  def call(self, features, mode):\n",
        "    inputs = self._input_layer(features)\n",
        "    for nn in self._dnn:\n",
        "        inputs = nn(inputs)\n",
        "    dnn_output = inputs\n",
        "    return dnn_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6d874cea-2b55-449e-a087-e19ad3ea17ff",
      "metadata": {
        "id": "6d874cea-2b55-449e-a087-e19ad3ea17ff"
      },
      "outputs": [],
      "source": [
        "class WideDeepModel(tf.estimator.Estimator):\n",
        "\n",
        "    def __init__(self, model_dir=None, config=None, warm_start_from=None, wide_columns=None, linear_optimizer=None,\n",
        "                 deep_columns=None, dnn_optimizer=None):\n",
        "\n",
        "        def _model_fn(features, labels, mode, config):\n",
        "            \n",
        "            # wide & deep\n",
        "            linear_logits, linear_trainable_variables = wide_model(units=1, feature_columns=wide_columns, sparse_combiner='sum', features=features)\n",
        "            \n",
        "            deep_model = DNN(deep_columns=deep_columns, name='dnn')\n",
        "            dnn_logits = deep_model(features, mode)\n",
        "            dnn_trainable_variables = deep_model.trainable_variables\n",
        "            dnn_update_ops = deep_model.updates\n",
        "\n",
        "            logistic_output = dict()\n",
        "            logistic_output['ctr'] = tf.sigmoid(dnn_logits + linear_logits)\n",
        "\n",
        "            obj_head = []\n",
        "            ctr_head = tf.estimator.BinaryClassHead(weight_column=None, name='ctr')\n",
        "            obj_head.append(ctr_head)\n",
        "            multi_head = tf.estimator.MultiHead(obj_head)\n",
        "\n",
        "\n",
        "            def _train_op_fn(loss):\n",
        "                \"\"\"Returns the op to optimize the loss.\"\"\"\n",
        "                train_ops = []\n",
        "                if dnn_logits is not None:\n",
        "                    train_ops.extend(dnn_optimizer.get_updates(loss, dnn_trainable_variables))\n",
        "                if dnn_update_ops is not None:\n",
        "                    train_ops.extend(dnn_update_ops)\n",
        "                if linear_logits is not None:\n",
        "                    train_ops.extend(linear_optimizer.get_updates(loss, linear_trainable_variables))\n",
        "                train_op = tf.group(*train_ops)\n",
        "                return train_op\n",
        "\n",
        "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "              # In TRAIN mode, asssign global_step variable to optimizer.iterations to\n",
        "              # make global_step increased correctly, as Hooks relies on global step as\n",
        "              # step counter. Note that, Only one model's optimizer needs this assignment.\n",
        "                if dnn_logits is not None:\n",
        "                    dnn_optimizer.iterations = tf.compat.v1.train.get_or_create_global_step()\n",
        "                else:\n",
        "                    linear_optimizer.iterations = tf.compat.v1.train.get_or_create_global_step()\n",
        "    \n",
        "            return multi_head.create_estimator_spec(features=features, mode=mode, labels=labels, train_op_fn=_train_op_fn, logits=logistic_output)\n",
        "\n",
        "        super(WideDeepModel, self).__init__(model_fn=_model_fn, model_dir=model_dir, config=config, warm_start_from=warm_start_from)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ChP0BREzKQ2O"
      },
      "id": "ChP0BREzKQ2O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0957ea72-e3fc-4450-b039-f5f0be5140a2",
      "metadata": {
        "id": "0957ea72-e3fc-4450-b039-f5f0be5140a2"
      },
      "source": [
        "### Estimator模型的生命周期"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7b8664ac",
      "metadata": {
        "id": "7b8664ac"
      },
      "outputs": [],
      "source": [
        "tf.compat.v1.disable_eager_execution()\n",
        "batch_size = 8\n",
        "epochs = 6\n",
        "sample_nums = 3060\n",
        "max_steps = int(sample_nums * epochs / batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "87daf2d2-633e-42a4-8549-5c2e0a592f77",
      "metadata": {
        "id": "87daf2d2-633e-42a4-8549-5c2e0a592f77"
      },
      "outputs": [],
      "source": [
        "def _serving_input_receiver_fn(serving_feature):\n",
        "    '''expects all features to be fed directly.'''\n",
        "    features = {}\n",
        "    for feature_name, _ in serving_feature.items():\n",
        "        if 'dense' in feature_name:\n",
        "            features[feature_name] = tf.compat.v1.placeholder(dtype=tf.float32, shape=[None, None])\n",
        "        elif 'sparse' in feature_name:\n",
        "            features[feature_name] = tf.compat.v1.placeholder(dtype=tf.int64, shape=[None, None])\n",
        "        else:\n",
        "            print('exception feature type')\n",
        "    return tf.estimator.export.build_raw_serving_input_receiver_fn(features)\n",
        "\n",
        "def auc_compare_fn(best_eval_result, current_eval_result ):\n",
        "    return best_eval_result['auc/ctr'] < current_eval_result['act/ctr']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "475c4a0e-966f-49a9-b263-554950427579",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "475c4a0e-966f-49a9-b263-554950427579",
        "outputId": "b3f4d011-8546-4a3c-9243-423aec2c4939"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:TF_CONFIG environment variable: {'task': {'type': 'worker', 'index': 0}}\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': './model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ]
        }
      ],
      "source": [
        "train_model_spec = tf.estimator.TrainSpec(input_fn=_input_fn('./data/simple.tfrecord', feature_proto), max_steps=max_steps)\n",
        "\n",
        "model_exporter = tf.estimator.BestExporter(\n",
        "    serving_input_receiver_fn=_serving_input_receiver_fn(serving_feature),\n",
        "    compare_fn=auc_compare_fn,\n",
        "    exports_to_keep=4)\n",
        "\n",
        "eval_model_spec = tf.estimator.EvalSpec(input_fn=_input_fn('./data/simple.tfrecord', feature_proto),\n",
        "                                  steps=10,\n",
        "                                  throttle_secs=3,\n",
        "                                  exporters=model_exporter)\n",
        "\n",
        "wd_model = WideDeepModel(model_dir='./model',\n",
        "                         wide_columns=wide_columns,\n",
        "                         linear_optimizer=tf.keras.optimizers.Ftrl(learning_rate=0.001,l1_regularization_strength=0.05,l2_regularization_strength=0.2),\n",
        "                         deep_columns=deep_columns,\n",
        "                         dnn_optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.008, epsilon=1e-8))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fda7a600",
      "metadata": {
        "id": "fda7a600"
      },
      "source": [
        "train、eval、exporter各参数配置的具体含义。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2d339b7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d339b7c",
        "outputId": "1fb87b6d-3790-4efb-d5cf-7f35fa6ad089"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:397: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/canned/linear.py:1478: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  getter=tf.compat.v1.get_variable)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adagrad.py:84: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into ./model/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 0.97846556, step = 0\n",
            "INFO:tensorflow:global_step/sec: 237.074\n",
            "INFO:tensorflow:loss = 0.508775, step = 100 (0.428 sec)\n",
            "INFO:tensorflow:global_step/sec: 532.508\n",
            "INFO:tensorflow:loss = 0.680966, step = 200 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.162\n",
            "INFO:tensorflow:loss = 0.7166904, step = 300 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 514.63\n",
            "INFO:tensorflow:loss = 0.77224016, step = 400 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 562.815\n",
            "INFO:tensorflow:loss = 0.7436389, step = 500 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 512.766\n",
            "INFO:tensorflow:loss = 0.6423338, step = 600 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 551.403\n",
            "INFO:tensorflow:loss = 0.65664923, step = 700 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 530.326\n",
            "INFO:tensorflow:loss = 0.73862255, step = 800 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 535.799\n",
            "INFO:tensorflow:loss = 0.7351351, step = 900 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 562.757\n",
            "INFO:tensorflow:loss = 0.69622076, step = 1000 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.737\n",
            "INFO:tensorflow:loss = 0.7084725, step = 1100 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.032\n",
            "INFO:tensorflow:loss = 0.7249914, step = 1200 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 550.197\n",
            "INFO:tensorflow:loss = 0.73434687, step = 1300 (0.183 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1302 vs previous value: 1302. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 505.64\n",
            "INFO:tensorflow:loss = 0.72209036, step = 1400 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 556.383\n",
            "INFO:tensorflow:loss = 0.6931472, step = 1500 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 573.654\n",
            "INFO:tensorflow:loss = 0.7202515, step = 1600 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.083\n",
            "INFO:tensorflow:loss = 0.67175996, step = 1700 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 550.099\n",
            "INFO:tensorflow:loss = 0.77268416, step = 1800 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 334.23\n",
            "INFO:tensorflow:loss = 0.64692354, step = 1900 (0.304 sec)\n",
            "INFO:tensorflow:global_step/sec: 243.959\n",
            "INFO:tensorflow:loss = 0.71732545, step = 2000 (0.405 sec)\n",
            "INFO:tensorflow:global_step/sec: 265.838\n",
            "INFO:tensorflow:loss = 0.6687857, step = 2100 (0.377 sec)\n",
            "INFO:tensorflow:global_step/sec: 297.508\n",
            "INFO:tensorflow:loss = 0.65208554, step = 2200 (0.339 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 2271 vs previous value: 2271. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2295...\n",
            "INFO:tensorflow:Saving checkpoints for 2295 into ./model/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2295...\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2022-05-05T12:12:55\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from ./model/model.ckpt-2295\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [1/10]\n",
            "INFO:tensorflow:Evaluation [2/10]\n",
            "INFO:tensorflow:Evaluation [3/10]\n",
            "INFO:tensorflow:Evaluation [4/10]\n",
            "INFO:tensorflow:Evaluation [5/10]\n",
            "INFO:tensorflow:Evaluation [6/10]\n",
            "INFO:tensorflow:Evaluation [7/10]\n",
            "INFO:tensorflow:Evaluation [8/10]\n",
            "INFO:tensorflow:Evaluation [9/10]\n",
            "INFO:tensorflow:Evaluation [10/10]\n",
            "INFO:tensorflow:Inference Time : 0.99822s\n",
            "INFO:tensorflow:Finished evaluation at 2022-05-05-12:12:56\n",
            "INFO:tensorflow:Saving dict for global step 2295: accuracy/ctr = 0.525, accuracy_baseline/ctr = 0.525, auc/ctr = 0.65914786, auc_precision_recall/ctr = 0.6532924, average_loss/ctr = 0.6762761, global_step = 2295, label/mean/ctr = 0.475, loss = 0.6762761, loss/ctr = 0.6762761, precision/ctr = 0.5, prediction/mean/ctr = 0.52568924, recall/ctr = 0.68421054\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2295: ./model/model.ckpt-2295\n",
            "INFO:tensorflow:Loading best metric from event files.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/summary/summary_iterator.py:27: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "INFO:tensorflow:Performing best model export.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:204: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['ctr/predict', 'predict']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
            "INFO:tensorflow:'serving_default' : Classification signatures can only accept a single tensor input of type tf.string. Please check to make sure that you have structured the serving_input_receiver_fn so that it creates a single string placeholder. If your model function expects multiple inputs, then use `tf.io.parse_example()` to parse the string into multiple tensors.\n",
            " Received: {'sparse_000': <tf.Tensor 'Placeholder:0' shape=(None, None) dtype=int64>, 'sparse_001': <tf.Tensor 'Placeholder_1:0' shape=(None, None) dtype=int64>, 'sparse_002': <tf.Tensor 'Placeholder_2:0' shape=(None, None) dtype=int64>, 'dense_000': <tf.Tensor 'Placeholder_3:0' shape=(None, None) dtype=float32>, 'dense_002': <tf.Tensor 'Placeholder_4:0' shape=(None, None) dtype=float32>, 'dense_003': <tf.Tensor 'Placeholder_5:0' shape=(None, None) dtype=float32>}\n",
            "INFO:tensorflow:'ctr' : Classification signatures can only accept a single tensor input of type tf.string. Please check to make sure that you have structured the serving_input_receiver_fn so that it creates a single string placeholder. If your model function expects multiple inputs, then use `tf.io.parse_example()` to parse the string into multiple tensors.\n",
            " Received: {'sparse_000': <tf.Tensor 'Placeholder:0' shape=(None, None) dtype=int64>, 'sparse_001': <tf.Tensor 'Placeholder_1:0' shape=(None, None) dtype=int64>, 'sparse_002': <tf.Tensor 'Placeholder_2:0' shape=(None, None) dtype=int64>, 'dense_000': <tf.Tensor 'Placeholder_3:0' shape=(None, None) dtype=float32>, 'dense_002': <tf.Tensor 'Placeholder_4:0' shape=(None, None) dtype=float32>, 'dense_003': <tf.Tensor 'Placeholder_5:0' shape=(None, None) dtype=float32>}\n",
            "INFO:tensorflow:'ctr/classification' : Classification signatures can only accept a single tensor input of type tf.string. Please check to make sure that you have structured the serving_input_receiver_fn so that it creates a single string placeholder. If your model function expects multiple inputs, then use `tf.io.parse_example()` to parse the string into multiple tensors.\n",
            " Received: {'sparse_000': <tf.Tensor 'Placeholder:0' shape=(None, None) dtype=int64>, 'sparse_001': <tf.Tensor 'Placeholder_1:0' shape=(None, None) dtype=int64>, 'sparse_002': <tf.Tensor 'Placeholder_2:0' shape=(None, None) dtype=int64>, 'dense_000': <tf.Tensor 'Placeholder_3:0' shape=(None, None) dtype=float32>, 'dense_002': <tf.Tensor 'Placeholder_4:0' shape=(None, None) dtype=float32>, 'dense_003': <tf.Tensor 'Placeholder_5:0' shape=(None, None) dtype=float32>}\n",
            "INFO:tensorflow:'ctr/regression' : Regression signatures can only accept a single tensor input of type tf.string. Please check to make sure that you have structured the serving_input_receiver_fn so that it creates a single string placeholder. If your model function expects multiple inputs, then use `tf.io.parse_example()` to parse the string into multiple tensors.\n",
            " Received: {'sparse_000': <tf.Tensor 'Placeholder:0' shape=(None, None) dtype=int64>, 'sparse_001': <tf.Tensor 'Placeholder_1:0' shape=(None, None) dtype=int64>, 'sparse_002': <tf.Tensor 'Placeholder_2:0' shape=(None, None) dtype=int64>, 'dense_000': <tf.Tensor 'Placeholder_3:0' shape=(None, None) dtype=float32>, 'dense_002': <tf.Tensor 'Placeholder_4:0' shape=(None, None) dtype=float32>, 'dense_003': <tf.Tensor 'Placeholder_5:0' shape=(None, None) dtype=float32>}\n",
            "WARNING:tensorflow:Export includes no default signature!\n",
            "INFO:tensorflow:Restoring parameters from ./model/model.ckpt-2295\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: ./model/export/best_exporter/temp-1651752777/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 0.7026119.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['ctr/predict', 'predict']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
            "INFO:tensorflow:'serving_default' : Classification signatures can only accept a single tensor input of type tf.string. Please check to make sure that you have structured the serving_input_receiver_fn so that it creates a single string placeholder. If your model function expects multiple inputs, then use `tf.io.parse_example()` to parse the string into multiple tensors.\n",
            " Received: {'sparse_000': <tf.Tensor 'Placeholder_6:0' shape=(None, None) dtype=int64>, 'sparse_001': <tf.Tensor 'Placeholder_7:0' shape=(None, None) dtype=int64>, 'sparse_002': <tf.Tensor 'Placeholder_8:0' shape=(None, None) dtype=int64>, 'dense_000': <tf.Tensor 'Placeholder_9:0' shape=(None, None) dtype=float32>, 'dense_002': <tf.Tensor 'Placeholder_10:0' shape=(None, None) dtype=float32>, 'dense_003': <tf.Tensor 'Placeholder_11:0' shape=(None, None) dtype=float32>}\n",
            "INFO:tensorflow:'ctr' : Classification signatures can only accept a single tensor input of type tf.string. Please check to make sure that you have structured the serving_input_receiver_fn so that it creates a single string placeholder. If your model function expects multiple inputs, then use `tf.io.parse_example()` to parse the string into multiple tensors.\n",
            " Received: {'sparse_000': <tf.Tensor 'Placeholder_6:0' shape=(None, None) dtype=int64>, 'sparse_001': <tf.Tensor 'Placeholder_7:0' shape=(None, None) dtype=int64>, 'sparse_002': <tf.Tensor 'Placeholder_8:0' shape=(None, None) dtype=int64>, 'dense_000': <tf.Tensor 'Placeholder_9:0' shape=(None, None) dtype=float32>, 'dense_002': <tf.Tensor 'Placeholder_10:0' shape=(None, None) dtype=float32>, 'dense_003': <tf.Tensor 'Placeholder_11:0' shape=(None, None) dtype=float32>}\n",
            "INFO:tensorflow:'ctr/classification' : Classification signatures can only accept a single tensor input of type tf.string. Please check to make sure that you have structured the serving_input_receiver_fn so that it creates a single string placeholder. If your model function expects multiple inputs, then use `tf.io.parse_example()` to parse the string into multiple tensors.\n",
            " Received: {'sparse_000': <tf.Tensor 'Placeholder_6:0' shape=(None, None) dtype=int64>, 'sparse_001': <tf.Tensor 'Placeholder_7:0' shape=(None, None) dtype=int64>, 'sparse_002': <tf.Tensor 'Placeholder_8:0' shape=(None, None) dtype=int64>, 'dense_000': <tf.Tensor 'Placeholder_9:0' shape=(None, None) dtype=float32>, 'dense_002': <tf.Tensor 'Placeholder_10:0' shape=(None, None) dtype=float32>, 'dense_003': <tf.Tensor 'Placeholder_11:0' shape=(None, None) dtype=float32>}\n",
            "INFO:tensorflow:'ctr/regression' : Regression signatures can only accept a single tensor input of type tf.string. Please check to make sure that you have structured the serving_input_receiver_fn so that it creates a single string placeholder. If your model function expects multiple inputs, then use `tf.io.parse_example()` to parse the string into multiple tensors.\n",
            " Received: {'sparse_000': <tf.Tensor 'Placeholder_6:0' shape=(None, None) dtype=int64>, 'sparse_001': <tf.Tensor 'Placeholder_7:0' shape=(None, None) dtype=int64>, 'sparse_002': <tf.Tensor 'Placeholder_8:0' shape=(None, None) dtype=int64>, 'dense_000': <tf.Tensor 'Placeholder_9:0' shape=(None, None) dtype=float32>, 'dense_002': <tf.Tensor 'Placeholder_10:0' shape=(None, None) dtype=float32>, 'dense_003': <tf.Tensor 'Placeholder_11:0' shape=(None, None) dtype=float32>}\n",
            "WARNING:tensorflow:Export includes no default signature!\n",
            "INFO:tensorflow:Restoring parameters from ./model/model.ckpt-2295\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: ./model/saved_model/temp-1651752786/saved_model.pb\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'./model/saved_model/1651752786'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "!rm -rf ./model\n",
        "tf.estimator.train_and_evaluate(wd_model, train_model_spec, eval_model_spec)\n",
        "wd_model.export_saved_model(\"./model/saved_model\", _serving_input_receiver_fn(serving_feature))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "3215e7e3-a8c6-4c50-9124-d6ace083b2bc",
      "metadata": {
        "id": "3215e7e3-a8c6-4c50-9124-d6ace083b2bc"
      },
      "outputs": [],
      "source": [
        "# 基于estimator自带Wide-n-Deep model\n",
        "# from tensorflow.estimator import DNNLinearCombinedClassifier as WideDeepModelV2\n",
        "# wd_model_v2 = WideDeepModelV2(model_dir='./model',\n",
        "#                               linear_feature_columns=wide_columns,\n",
        "#                               dnn_feature_columns=deep_columns,\n",
        "#                               dnn_hidden_units = [16, 8])\n",
        "# tf.estimator.train_and_evaluate(wd_model_v2, train_model_spec, eval_model_spec)\n",
        "# wd_model_v2.export_saved_model(\"./model/saved_model\", _serving_input_receiver_fn(serving_feature))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "5c4b03b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c4b03b8",
        "outputId": "f5c06899-c4c3-4839-b8e7-5dcebeaff69c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['dense_000'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, -1)\n",
            "      name: Placeholder_9:0\n",
            "  inputs['dense_002'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, -1)\n",
            "      name: Placeholder_10:0\n",
            "  inputs['dense_003'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, -1)\n",
            "      name: Placeholder_11:0\n",
            "  inputs['sparse_000'] tensor_info:\n",
            "      dtype: DT_INT64\n",
            "      shape: (-1, -1)\n",
            "      name: Placeholder_6:0\n",
            "  inputs['sparse_001'] tensor_info:\n",
            "      dtype: DT_INT64\n",
            "      shape: (-1, -1)\n",
            "      name: Placeholder_7:0\n",
            "  inputs['sparse_002'] tensor_info:\n",
            "      dtype: DT_INT64\n",
            "      shape: (-1, -1)\n",
            "      name: Placeholder_8:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['ctr/all_class_ids'] tensor_info:\n",
            "      dtype: DT_INT32\n",
            "      shape: (-1, 2)\n",
            "      name: ctr/ctr/predictions/Tile:0\n",
            "  outputs['ctr/all_classes'] tensor_info:\n",
            "      dtype: DT_STRING\n",
            "      shape: (-1, 2)\n",
            "      name: ctr/ctr/predictions/Tile_1:0\n",
            "  outputs['ctr/class_ids'] tensor_info:\n",
            "      dtype: DT_INT64\n",
            "      shape: (-1, 1)\n",
            "      name: ctr/ctr/predictions/ExpandDims:0\n",
            "  outputs['ctr/classes'] tensor_info:\n",
            "      dtype: DT_STRING\n",
            "      shape: (-1, 1)\n",
            "      name: ctr/ctr/predictions/str_classes:0\n",
            "  outputs['ctr/logistic'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 1)\n",
            "      name: ctr/ctr/predictions/logistic:0\n",
            "  outputs['ctr/logits'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 1)\n",
            "      name: Sigmoid:0\n",
            "  outputs['ctr/probabilities'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 2)\n",
            "      name: ctr/ctr/predictions/probabilities:0\n",
            "Method name is: tensorflow/serving/predict\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --dir ./model/saved_model/*/ --tag_set serve --signature_def predict"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "00-Wide&Deep.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
