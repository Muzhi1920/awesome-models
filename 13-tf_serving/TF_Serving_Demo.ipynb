{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muzhi1920/awesome-models/blob/main/13-tf_serving/TF_Serving_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FvzT_HQXz9J"
      },
      "source": [
        "# 面向初学者的TensorFlow Serving服务（gRPC）实践\n",
        "\n",
        "之前几篇文章，分别简介了基于tf.estimator实现简易wide&deep模型的训练（参考[wide&deep](https://zhuanlan.zhihu.com/p/510886354)），以及gRPC服务基础（参考[grpc-demo](https://zhuanlan.zhihu.com/p/518605682)）。本文继续介绍基于tensorflow serving实现的模型部署与推理服务，主要包括：\n",
        "\n",
        "1. 服务模型准备\n",
        "2. tf-serving环境的搭建\n",
        "3. client实现模型调用服务\n",
        "4. 模型输出与多目标融合\n",
        "\n",
        "另基于restful api实现的json调取可以参考[rest_simple](https://www.tensorflow.org/tfx/tutorials/serving/rest_simple)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoIj2728pLyw"
      },
      "source": [
        "## 准备Wide&Deep Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyNr6Rhh82mD",
        "outputId": "8d636742-4f46-4520-8c7a-d87009b251c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3bC--0GXz9O"
      },
      "source": [
        "当前文件夹包含该模型。另Google Colab下模型路径，simple model store here[wide&deep](https://drive.google.com/file/d/1DpUKkqvGYs2kTSvUWglG-yRzOzIdSCUU/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "D2WdEW-Q82mF"
      },
      "outputs": [],
      "source": [
        "model_path = \"/content/drive/MyDrive/saved_model\"\n",
        "version = \"1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VV7onOD2Xz9P"
      },
      "source": [
        "### 检查saved model\n",
        "\n",
        "TensorFlow通过`saved_model_cli`工具检查saved model的inouts和output。这里model可以确定多个`signature`（签名），比如`serving_default`，`predict`等等。其中每一套`signature`分别对应相同的输入和不同的输出，以满足不同需要。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lgzz06XoXz9Q",
        "outputId": "55d289e7-5c8e-4b2d-aae6-d2e4ee5cac68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['ctr/predict']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['dense_000'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, -1)\n",
            "        name: Placeholder_21:0\n",
            "    inputs['dense_002'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, -1)\n",
            "        name: Placeholder_22:0\n",
            "    inputs['dense_003'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, -1)\n",
            "        name: Placeholder_23:0\n",
            "    inputs['sparse_000'] tensor_info:\n",
            "        dtype: DT_INT64\n",
            "        shape: (-1, -1)\n",
            "        name: Placeholder_18:0\n",
            "    inputs['sparse_001'] tensor_info:\n",
            "        dtype: DT_INT64\n",
            "        shape: (-1, -1)\n",
            "        name: Placeholder_19:0\n",
            "    inputs['sparse_002'] tensor_info:\n",
            "        dtype: DT_INT64\n",
            "        shape: (-1, -1)\n",
            "        name: Placeholder_20:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['all_class_ids'] tensor_info:\n",
            "        dtype: DT_INT32\n",
            "        shape: (-1, 2)\n",
            "        name: ctr/ctr/predictions/Tile:0\n",
            "    outputs['all_classes'] tensor_info:\n",
            "        dtype: DT_STRING\n",
            "        shape: (-1, 2)\n",
            "        name: ctr/ctr/predictions/Tile_1:0\n",
            "    outputs['class_ids'] tensor_info:\n",
            "        dtype: DT_INT64\n",
            "        shape: (-1, 1)\n",
            "        name: ctr/ctr/predictions/ExpandDims:0\n",
            "    outputs['classes'] tensor_info:\n",
            "        dtype: DT_STRING\n",
            "        shape: (-1, 1)\n",
            "        name: ctr/ctr/predictions/str_classes:0\n",
            "    outputs['logistic'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 1)\n",
            "        name: ctr/ctr/predictions/logistic:0\n",
            "    outputs['logits'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 1)\n",
            "        name: Sigmoid:0\n",
            "    outputs['probabilities'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 2)\n",
            "        name: ctr/ctr/predictions/probabilities:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "\n",
            "signature_def['predict']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['dense_000'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, -1)\n",
            "        name: Placeholder_21:0\n",
            "    inputs['dense_002'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, -1)\n",
            "        name: Placeholder_22:0\n",
            "    inputs['dense_003'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, -1)\n",
            "        name: Placeholder_23:0\n",
            "    inputs['sparse_000'] tensor_info:\n",
            "        dtype: DT_INT64\n",
            "        shape: (-1, -1)\n",
            "        name: Placeholder_18:0\n",
            "    inputs['sparse_001'] tensor_info:\n",
            "        dtype: DT_INT64\n",
            "        shape: (-1, -1)\n",
            "        name: Placeholder_19:0\n",
            "    inputs['sparse_002'] tensor_info:\n",
            "        dtype: DT_INT64\n",
            "        shape: (-1, -1)\n",
            "        name: Placeholder_20:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['ctr/all_class_ids'] tensor_info:\n",
            "        dtype: DT_INT32\n",
            "        shape: (-1, 2)\n",
            "        name: ctr/ctr/predictions/Tile:0\n",
            "    outputs['ctr/all_classes'] tensor_info:\n",
            "        dtype: DT_STRING\n",
            "        shape: (-1, 2)\n",
            "        name: ctr/ctr/predictions/Tile_1:0\n",
            "    outputs['ctr/class_ids'] tensor_info:\n",
            "        dtype: DT_INT64\n",
            "        shape: (-1, 1)\n",
            "        name: ctr/ctr/predictions/ExpandDims:0\n",
            "    outputs['ctr/classes'] tensor_info:\n",
            "        dtype: DT_STRING\n",
            "        shape: (-1, 1)\n",
            "        name: ctr/ctr/predictions/str_classes:0\n",
            "    outputs['ctr/logistic'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 1)\n",
            "        name: ctr/ctr/predictions/logistic:0\n",
            "    outputs['ctr/logits'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 1)\n",
            "        name: Sigmoid:0\n",
            "    outputs['ctr/probabilities'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 2)\n",
            "        name: ctr/ctr/predictions/probabilities:0\n",
            "  Method name is: tensorflow/serving/predict\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --dir {model_path}/{version} --all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoLroXHE82mJ"
      },
      "source": [
        "## 搭建TensorFlow-Serving的service\n",
        "\n",
        "搭建tensorflow model server服务环境，执行如下命令安装："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDVz8VnnXz9Q",
        "outputId": "9a777dd0-09ce-4354-85df-546e727f6fa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  2943  100  2943    0     0  14217      0 --:--:-- --:--:-- --:--:-- 14217\n",
            "OK\n",
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:3 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,012 B]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 Packages [341 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:12 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server-universal amd64 Packages [349 B]\n",
            "Hit:13 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,799 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:16 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,286 kB]\n",
            "Hit:18 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,992 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,512 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,231 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,021 kB]\n",
            "Get:23 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Fetched 13.2 MB in 7s (1,909 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "45 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ]
        }
      ],
      "source": [
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -\n",
        "!sudo apt update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2HQb4q6sonS",
        "outputId": "ce6e20ab-d031-4158-ec23-694dbb99c0b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  tensorflow-model-server\n",
            "0 upgraded, 1 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 340 MB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 tensorflow-model-server all 2.8.0 [340 MB]\n",
            "Fetched 340 MB in 6s (59.7 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tensorflow-model-server.\n",
            "(Reading database ... 155632 files and directories currently installed.)\n",
            "Preparing to unpack .../tensorflow-model-server_2.8.0_all.deb ...\n",
            "Unpacking tensorflow-model-server (2.8.0) ...\n",
            "Setting up tensorflow-model-server (2.8.0) ...\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install tensorflow-model-server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jn9oNYM7pYcv"
      },
      "source": [
        "### 启动TF Serving服务"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Mq4t5ozVXz9R"
      },
      "outputs": [],
      "source": [
        "!nohup tensorflow_model_server \\\n",
        "  --port=8502   \\\n",
        "  --model_name='wide&deep' \\\n",
        "  --model_base_path=$model_path >server.log 2>&1 &"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVxpP7nM_urH"
      },
      "source": [
        "更多参数配置参考[offical code](https://github.com/tensorflow/serving/blob/master/tensorflow_serving/model_servers/main.cc#L59)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVhTO53jXz9S",
        "outputId": "0395c5e3-3d88-4b1f-959e-8017cd956467"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-06 12:51:58.645494: I tensorflow_serving/model_servers/server.cc:89] Building single TensorFlow model file config:  model_name: wide&deep model_base_path: /content/drive/MyDrive/saved_model\n",
            "2022-06-06 12:51:58.645789: I tensorflow_serving/model_servers/server_core.cc:465] Adding/updating models.\n",
            "2022-06-06 12:51:58.645828: I tensorflow_serving/model_servers/server_core.cc:594]  (Re-)adding model: wide&deep\n",
            "2022-06-06 12:51:58.750550: I tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: wide&deep version: 1}\n",
            "2022-06-06 12:51:58.750645: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: wide&deep version: 1}\n",
            "2022-06-06 12:51:58.750669: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: wide&deep version: 1}\n",
            "2022-06-06 12:51:58.751063: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /content/drive/MyDrive/saved_model/1\n",
            "2022-06-06 12:51:58.755777: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
            "2022-06-06 12:51:58.755895: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /content/drive/MyDrive/saved_model/1\n",
            "2022-06-06 12:51:58.756302: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-06-06 12:51:58.800522: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
            "2022-06-06 12:51:59.896048: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /content/drive/MyDrive/saved_model/1\n",
            "2022-06-06 12:51:59.905023: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1153953 microseconds.\n",
            "2022-06-06 12:51:59.906808: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /content/drive/MyDrive/saved_model/1/assets.extra/tf_serving_warmup_requests\n",
            "2022-06-06 12:51:59.912289: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: wide&deep version: 1}\n",
            "2022-06-06 12:51:59.913682: I tensorflow_serving/model_servers/server_core.cc:486] Finished adding/updating models\n",
            "2022-06-06 12:51:59.913770: I tensorflow_serving/model_servers/server.cc:133] Using InsecureServerCredentials\n",
            "2022-06-06 12:51:59.913787: I tensorflow_serving/model_servers/server.cc:391] Profiler service is enabled\n",
            "2022-06-06 12:51:59.914292: I tensorflow_serving/model_servers/server.cc:417] Running gRPC ModelServer at 0.0.0.0:8502 ...\n"
          ]
        }
      ],
      "source": [
        "!cat server.log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE7_DvFeYzus",
        "outputId": "836fea8e-dc3d-469d-ce07-8566cc0f1571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "node         7 root   21u  IPv6  26401      0t0  TCP *:8080 (LISTEN)\n",
            "colab-fil   29 root    5u  IPv6  26379      0t0  TCP *:3453 (LISTEN)\n",
            "colab-fil   29 root    6u  IPv4  26380      0t0  TCP *:3453 (LISTEN)\n",
            "jupyter-n   42 root    6u  IPv4  27118      0t0  TCP 172.28.0.2:9000 (LISTEN)\n",
            "python3     60 root   15u  IPv4  30693      0t0  TCP 127.0.0.1:44337 (LISTEN)\n",
            "python3     60 root   18u  IPv4  30697      0t0  TCP 127.0.0.1:47445 (LISTEN)\n",
            "python3     60 root   21u  IPv4  30701      0t0  TCP 127.0.0.1:44631 (LISTEN)\n",
            "python3     60 root   24u  IPv4  30705      0t0  TCP 127.0.0.1:59491 (LISTEN)\n",
            "python3     60 root   30u  IPv4  30711      0t0  TCP 127.0.0.1:34909 (LISTEN)\n",
            "python3     60 root   44u  IPv4  32779      0t0  TCP 127.0.0.1:45987 (LISTEN)\n",
            "python3     80 root    3u  IPv4  33061      0t0  TCP 127.0.0.1:21623 (LISTEN)\n",
            "python3     80 root    4u  IPv4  33062      0t0  TCP 127.0.0.1:33817 (LISTEN)\n",
            "python3     80 root    9u  IPv4  32093      0t0  TCP 127.0.0.1:40787 (LISTEN)\n",
            "tensorflo 1576 root    5u  IPv4  44155      0t0  TCP *:8502 (LISTEN)\n"
          ]
        }
      ],
      "source": [
        "# 查看`port`开启状态\n",
        "!sudo lsof -i -P -n | grep LISTEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea6V73oXzs3U"
      },
      "source": [
        "能够发现指定tf-serving服务的gRPC端口`8502`。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Com8Mcu2Xz9L"
      },
      "source": [
        "## 搭建Tensorflow-Serving的client\n",
        "\n",
        "TensorFlow运行时是`懒加载（初始化）`的，首次请求引发大量延时（参考[TensorFlow Serving 模型更新毛刺的完全优化实践](https://mp.weixin.qq.com/s/DkCGusznH8F8p39oRLuNBQ)），为了降低懒加载的请求延迟，构建部分随机样本去初始化变量和各node。预热以后再接入外部请求。这个过程就是模型的预热。生成模型的预热文件，可参考 [official document](https://www.tensorflow.org/tfx/serving/saved_model_warmup)\n",
        "\n",
        ">上面模型部署的server.log日志中其实也提示了` No warmup data file found `"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "b-aGIWy8c2Ht"
      },
      "outputs": [],
      "source": [
        "# 安装本地client所需pkg\n",
        "!pip install -q requests\n",
        "!pip install -q tensorflow-serving-api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6lQVylcMXz9N"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import json\n",
        "import requests\n",
        "\n",
        "import grpc\n",
        "from tensorflow_serving.apis import predict_pb2\n",
        "from tensorflow_serving.apis import prediction_service_pb2_grpc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vov_9BqR82mO"
      },
      "source": [
        "prediction_service_pb2_grpc通过[`prediction_service.proto`](https://github.com/tensorflow/serving/blob/master/tensorflow_serving/apis/prediction_service.proto)定义了大量接口，几乎包含所有请求类型的rpc service，包括`Classify`，`Regress`，`Predict`，`MultiInference`，`GetModelMetadata`。\n",
        "\n",
        "这里使用的是`predict`的rpc service，由[`predict.proto`](https://github.com/tensorflow/serving/blob/master/tensorflow_serving/apis/predict.proto)定义请求和响应。该接口定义了所运行的TensorFlow Model，以及对应输入的tensor和输出filter。其中推理所需特征字段的定义声明为`map<string, TensorProto> inputs = 2;`，因此传入的是由feature_name映射到feature_tensor的一个feature_dict。\n",
        "\n",
        "其他所有`proto`定义移步到[apis_proto](https://github.com/tensorflow/serving/tree/master/tensorflow_serving/apis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr7vO8BQrP2S"
      },
      "source": [
        "### 接入模型的gRPC服务\n",
        "主要的predict proto为\n",
        "```proto\n",
        "message PredictRequest {\n",
        "  ModelSpec model_spec = 1;  //请求model的信息，model_name + model_version 唯一确定\n",
        "  map<string, TensorProto> inputs = 2; //传入feature的dict\n",
        "  repeated string output_filter = 3; //输出过滤\n",
        "}\n",
        "\n",
        "message PredictResponse {\n",
        "  ModelSpec model_spec = 2; //返回model的信息\n",
        "  map<string, TensorProto> outputs = 1; //返回score的dict\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Y1cxieBDfyjK"
      },
      "outputs": [],
      "source": [
        "channel = grpc.insecure_channel('localhost:8502')\n",
        "stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS5b0VVfrTmF"
      },
      "source": [
        "### 创建model server请求"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2QD8xK47emy5"
      },
      "outputs": [],
      "source": [
        "request = predict_pb2.PredictRequest()\n",
        "request.model_spec.name = 'wide&deep'\n",
        "request.model_spec.signature_name = 'predict'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHwn0ZCu82mP"
      },
      "source": [
        "#### 随机初始化feautre tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PyE_xIBbk2d1"
      },
      "outputs": [],
      "source": [
        "sparse_feature = ['sparse_000', 'sparse_001', 'sparse_002']\n",
        "dense_feature = ['dense_000', 'dense_002', 'dense_003']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsTaEiFlldJy",
        "outputId": "cc7b5f23-d7ff-4be7-d6b2-53536fbdc5b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_spec {\n",
              "  name: \"wide&deep\"\n",
              "  signature_name: \"predict\"\n",
              "}\n",
              "inputs {\n",
              "  key: \"dense_000\"\n",
              "  value {\n",
              "    dtype: DT_FLOAT\n",
              "    tensor_shape {\n",
              "      dim {\n",
              "        size: 8\n",
              "      }\n",
              "      dim {\n",
              "        size: 1\n",
              "      }\n",
              "    }\n",
              "    tensor_content: \"\\363P3?\\006\\034V\\277#.\\262?\\341\\360\\321=|\\245\\234\\277\\325\\277\\265\\277^\\nJ\\277)\\311\\237?\"\n",
              "  }\n",
              "}\n",
              "inputs {\n",
              "  key: \"dense_002\"\n",
              "  value {\n",
              "    dtype: DT_FLOAT\n",
              "    tensor_shape {\n",
              "      dim {\n",
              "        size: 8\n",
              "      }\n",
              "      dim {\n",
              "        size: 1\n",
              "      }\n",
              "    }\n",
              "    tensor_content: \"\\206\\235\\273?\\340\\305\\227\\275\\204\\351\\267\\276\\374&\\276\\277#\\\\\\302?_t\\367\\276\\232\\261?\\277\\221`\\264\\276\"\n",
              "  }\n",
              "}\n",
              "inputs {\n",
              "  key: \"dense_003\"\n",
              "  value {\n",
              "    dtype: DT_FLOAT\n",
              "    tensor_shape {\n",
              "      dim {\n",
              "        size: 8\n",
              "      }\n",
              "      dim {\n",
              "        size: 1\n",
              "      }\n",
              "    }\n",
              "    tensor_content: \"`\\374\\376?<\\214&\\277\\264\\226t?\\037K\\022\\300\\032\\271B?>\\263\\365<,X\\376\\277Q\\367\\330?\"\n",
              "  }\n",
              "}\n",
              "inputs {\n",
              "  key: \"sparse_000\"\n",
              "  value {\n",
              "    dtype: DT_INT64\n",
              "    tensor_shape {\n",
              "      dim {\n",
              "        size: 8\n",
              "      }\n",
              "      dim {\n",
              "        size: 3\n",
              "      }\n",
              "    }\n",
              "    tensor_content: \"\\334\\\"]\\004\\000\\000\\000\\000\\017V\\'\\002\\000\\000\\000\\000x\\251)\\005\\000\\000\\000\\000P\\010\\031\\001\\000\\000\\000\\000\\030\\244\\\"\\005\\000\\000\\000\\000\\354S\\242\\002\\000\\000\\000\\000\\305\\035l\\002\\000\\000\\000\\000C\\247c\\004\\000\\000\\000\\000!\\037\\225\\005\\000\\000\\000\\000\\034/\\201\\005\\000\\000\\000\\000\\273\\034g\\005\\000\\000\\000\\000\\217fh\\005\\000\\000\\000\\000\\016\\213\\023\\004\\000\\000\\000\\000\\344\\035\\034\\005\\000\\000\\000\\000I\\241I\\004\\000\\000\\000\\000a\\3707\\002\\000\\000\\000\\000>\\266\\346\\002\\000\\000\\000\\000\\006\\224\\033\\004\\000\\000\\000\\000=\\332\\243\\004\\000\\000\\000\\000,\\240h\\003\\000\\000\\000\\000U\\315\\253\\000\\000\\000\\000\\0001[\\307\\002\\000\\000\\000\\000\\277b\\276\\003\\000\\000\\000\\000+1\\n\\004\\000\\000\\000\\000\"\n",
              "  }\n",
              "}\n",
              "inputs {\n",
              "  key: \"sparse_001\"\n",
              "  value {\n",
              "    dtype: DT_INT64\n",
              "    tensor_shape {\n",
              "      dim {\n",
              "        size: 8\n",
              "      }\n",
              "      dim {\n",
              "        size: 3\n",
              "      }\n",
              "    }\n",
              "    tensor_content: \"\\276r\\367\\004\\000\\000\\000\\000Z\\000\\301\\002\\000\\000\\000\\000L\\004Z\\003\\000\\000\\000\\000\\377\\2166\\003\\000\\000\\000\\000x\\034\\016\\005\\000\\000\\000\\00030I\\003\\000\\000\\000\\000\\240\\004\\360\\002\\000\\000\\000\\000\\220B&\\003\\000\\000\\000\\000\\314\\317\\374\\004\\000\\000\\000\\000\\037si\\004\\000\\000\\000\\000\\344CM\\001\\000\\000\\000\\000\\360\\203\\206\\004\\000\\000\\000\\000p\\031r\\004\\000\\000\\000\\000?R\\342\\005\\000\\000\\000\\000\\342\\021g\\001\\000\\000\\000\\000\\341Y\\367\\001\\000\\000\\000\\000\\223\\342\\231\\005\\000\\000\\000\\000\\226\\223\\275\\005\\000\\000\\000\\000i\\227D\\001\\000\\000\\000\\000x\\347\\236\\003\\000\\000\\000\\0008\\014\\352\\002\\000\\000\\000\\000~\\177\\323\\003\\000\\000\\000\\000\\007f\\245\\003\\000\\000\\000\\000\\364u\\037\\004\\000\\000\\000\\000\"\n",
              "  }\n",
              "}\n",
              "inputs {\n",
              "  key: \"sparse_002\"\n",
              "  value {\n",
              "    dtype: DT_INT64\n",
              "    tensor_shape {\n",
              "      dim {\n",
              "        size: 8\n",
              "      }\n",
              "      dim {\n",
              "        size: 3\n",
              "      }\n",
              "    }\n",
              "    tensor_content: \"\\314\\253R\\001\\000\\000\\000\\000+\\260\\005\\005\\000\\000\\000\\000/z\\003\\005\\000\\000\\000\\000\\263\\200\\361\\004\\000\\000\\000\\000\\375\\r\\201\\001\\000\\000\\000\\000\\330@\\373\\001\\000\\000\\000\\000Q\\306\\202\\001\\000\\000\\000\\000\\r\\215D\\002\\000\\000\\000\\000\\317\\025b\\001\\000\\000\\000\\000\\216\\241:\\001\\000\\000\\000\\000\\265\\233\\240\\002\\000\\000\\000\\000\\353#\\335\\000\\000\\000\\000\\000s9\\036\\004\\000\\000\\000\\000[t7\\002\\000\\000\\000\\000U\\326\\204\\003\\000\\000\\000\\000\\010\\t\\034\\002\\000\\000\\000\\000\\027\\013P\\002\\000\\000\\000\\000\\254\\356\\033\\003\\000\\000\\000\\000\\270\\254\\353\\002\\000\\000\\000\\000\\3448\\r\\005\\000\\000\\000\\0007\\263{\\004\\000\\000\\000\\000\\254q\\200\\005\\000\\000\\000\\000\\230\\242M\\001\\000\\000\\000\\000\\203\\0146\\005\\000\\000\\000\\000\"\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "for sf in sparse_feature:\n",
        "    dummy_sparse_feature = np.random.randint(10000000, 99999999, size=[8,3])\n",
        "    request.inputs[sf].CopyFrom(tf.make_tensor_proto(dummy_sparse_feature))\n",
        "\n",
        "for df in dense_feature:\n",
        "    dummy_dense_feature = np.random.normal(size=(8, 1))\n",
        "    request.inputs[df].CopyFrom(tf.make_tensor_proto(dummy_dense_feature, dtype=tf.float32))\n",
        "request"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UztXjZGrYTf"
      },
      "source": [
        "### 调用模型服务"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvslcT5_f4P6",
        "outputId": "d74eae59-b78d-43f9-8f30-cd0bec1f6a12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 180.38 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1000 loops, best of 5: 975 µs per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "result = stub.Predict(request, 10.0)  #timeout\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o52MnidprdCY"
      },
      "source": [
        "### 模型输出与多目标融合排序"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBfd4TG0f5z6",
        "outputId": "f4f36b8f-0f1e-404c-abda-f19c5de6d108"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(name: \"wide&deep\"\n",
              " version {\n",
              "   value: 1\n",
              " }\n",
              " signature_name: \"predict\",\n",
              " [0.6135268807411194, 0.6138688325881958, 0.6135810613632202, 0.611910879611969, 0.6130681037902832, 0.6125918626785278, 0.6142157912254333, 0.6139649748802185])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "grpc_predictions = stub.Predict(request, 10.0)\n",
        "ctr_output = grpc_predictions.outputs['ctr/logistic'].float_val\n",
        "grpc_predictions.model_spec,ctr_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPG1FhES82mR"
      },
      "source": [
        ">模型使用随机label训练的，发送的特征也是随机的，因此这里预估值的输出也是随机的。。。\n",
        "\n",
        "\n",
        "此处假设是多目标模型，那么输出的是多个预估值。多目标融合可以定义在model graph中，也可以写在返回的多个预估分钟。这里`PredictResponse`的proto定义为`map<string, TensorProto> outputs = 1;`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tBv8gOtP82mR"
      },
      "outputs": [],
      "source": [
        "ctr = grpc_predictions.outputs['ctr/logistic'].float_val\n",
        "#demo如下\n",
        "#vtr = grpc_predictions.outputs['vtr/logistic'].float_val，此处并非多目标模型，因此只包含ctr的输出值\n",
        "#pt = grpc_predictions.outputs['pt/logistic'].float_val\n",
        "#action = grpc_predictions.outputs['action/logistic'].float_val\n",
        "#final_score = mix_func(ctr,vtr,pt,action) # add, mul and so on..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQYFN_5a-WXP"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_1yxcQW_urM"
      },
      "source": [
        "## 结论\n",
        "\n",
        "通过窥探tensorflow_serving的相关proto定义，明确模型推理时所需的信息：\n",
        "\n",
        "1. model_spec：指定模型名及其版本号。每个确定的模型路径为唯一的`model_name/version`\n",
        "2. inputs：通过构造dict，确定传入的特征名到特征tensor的映射\n",
        "3. outputs：通过signature明确选择哪一套key-value输出\n",
        "\n",
        "基于此完成了model graph的前向计算和结果返回。对于不同的服务接口类型，在性能上也是不同的（比如吞吐量，最高并发量）。目前业界应用较广的还是基于k8s部署的tf-serving。可参考[ml-deployment-k8s-tfserving](https://github.com/deep-diver/ml-deployment-k8s-tfserving)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPSZYq8H_urN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TF_Serving_Demo.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "626869861cd3ed4fdbaf755d0ab61c53ee2a93056f2b69c4f7170d3cc24dc5ea"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
