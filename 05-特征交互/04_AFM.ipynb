{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_AFM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNh6y3vIUJjVYE1IVIj71wg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muzhi1920/awesome-models/blob/main/05-%E7%89%B9%E5%BE%81%E4%BA%A4%E4%BA%92/04_AFM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIdzg9vTXK4O"
      },
      "source": [
        "# AFM\n",
        "\n",
        "- 参考：Attentional Factorization Machines: Learning the Weight of Feature Interactions via Attention Networks\n",
        "- 论文：https://arxiv.org/pdf/1708.04617.pdf\n",
        "\n",
        "不同粒度间进行交叉，通过attention得到weight进行pooling\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiLw5lf14tIy"
      },
      "source": [
        "import tensorflow as tf\n",
        "from sequence_feature_layer import SequenceFeatures\n",
        "from tensorflow import feature_column as fc\n",
        "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout, Embedding, Conv1D\n",
        "import itertools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ9XCQ_54zMw"
      },
      "source": [
        "## 0.准备工作"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwWI_yGp4uVV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "944aab0d-d4fa-4922-911b-947f86f05f9e"
      },
      "source": [
        "seq_3101 = fc.sequence_categorical_column_with_hash_bucket('3101', hash_bucket_size=10, dtype=tf.int64)\n",
        "seq_3102 = fc.sequence_categorical_column_with_hash_bucket('3102', hash_bucket_size=10, dtype=tf.int64)\n",
        "target = fc.sequence_categorical_column_with_hash_bucket('target', hash_bucket_size=10, dtype=tf.int64)\n",
        "\n",
        "seq_3101_col = fc.embedding_column(seq_3101, dimension=8)\n",
        "seq_3102_col = fc.embedding_column(seq_3102, dimension=8)\n",
        "target_col = fc.embedding_column(target, dimension=8)\n",
        "columns = [seq_3101_col, seq_3102_col, target_col]\n",
        "features={\n",
        "  \"3101\": tf.sparse.SparseTensor(\n",
        "      indices=[[0, 0], [0, 1], [1, 0], [1, 1], [2, 0]],\n",
        "      values=[1100, 1101, 1102, 1101, 1103],\n",
        "      dense_shape=[3, 2]),\n",
        "  \"3102\": tf.sparse.SparseTensor(\n",
        "      indices=[[0, 0], [0, 1], [1, 0], [1, 1], [2, 0]],\n",
        "      values=[1000, 1001, 1002, 1001, 1003],\n",
        "      dense_shape=[3, 2]),\n",
        "  \"target\": tf.sparse.SparseTensor(\n",
        "      indices=[[0, 0],[1,0],[2,0]],\n",
        "      values=[1102,1103,1100],\n",
        "      dense_shape=[3, 1]),\n",
        "\n",
        "}\n",
        "tf.sparse.to_dense(features['3101'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              "array([[1100, 1101],\n",
              "       [1102, 1101],\n",
              "       [1103,    0]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dwuq4gg94uTN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e51caa6e-b354-4b28-f4cf-e2179ca0a933"
      },
      "source": [
        "sequence_feature_layer = SequenceFeatures(columns, name='sequence_features_input_layer')\n",
        "seq_emb_dict, seq_lengths = sequence_feature_layer(features)\n",
        "seq_emb_dict.keys(), seq_lengths.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dict_keys(['3101_embedding', '3102_embedding', 'target_embedding']),\n",
              " dict_keys(['3101_embedding', '3102_embedding', 'target_embedding']))"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72EE5W8O4uPC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da8c0162-60b6-4b67-ab6f-7ccd00116760"
      },
      "source": [
        "seq_mask_dict = {}\n",
        "for k, seq_length in seq_lengths.items():\n",
        "  seq_mask = tf.expand_dims(tf.where(tf.sequence_mask(seq_length), 1.0, 0.0),axis=-1)\n",
        "  seq_mask_dict[k] = seq_mask\n",
        "seq_mask_dict.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['3101_embedding', '3102_embedding', 'target_embedding'])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkGoI3keyp88"
      },
      "source": [
        "# 1.field粒度交叉与Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3VhZT217hBr"
      },
      "source": [
        "## 1.1Pair-wise Interaction Layer\n",
        "\n",
        ">对field粒度进行交互；长尾分布，对大部分稀疏id训练不好"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIk41_OHpm8C",
        "outputId": "867ed494-7397-4d18-9250-bc18fd947d0f"
      },
      "source": [
        "pwi_out=[]\n",
        "for r, c in itertools.combinations(list(seq_emb_dict.values()), 2):\n",
        "  r = tf.reduce_mean(r, axis=1)\n",
        "  c = tf.reduce_mean(c, axis=1)\n",
        "  pwi_out.append(tf.expand_dims(r*c,axis=1))\n",
        "pwi_out = tf.concat(pwi_out, axis=1)\n",
        "pwi_out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3, 8), dtype=float32, numpy=\n",
              "array([[[-1.00356073e-03,  9.98210069e-03,  4.71053598e-03,\n",
              "          1.10375509e-03, -3.21150455e-03, -6.51679412e-02,\n",
              "         -3.50311808e-02,  9.80597362e-03],\n",
              "        [-1.01555162e-03, -3.21287941e-03, -1.16679929e-02,\n",
              "         -4.28579078e-04, -8.31099600e-02,  5.17351553e-02,\n",
              "          7.88098052e-02, -8.96497630e-03],\n",
              "        [ 8.41867626e-02, -4.25591916e-02, -9.31518227e-02,\n",
              "         -1.86585579e-02,  5.19844750e-03, -3.24412584e-02,\n",
              "         -1.15362719e-01, -2.48533100e-01]],\n",
              "\n",
              "       [[ 8.18544030e-02, -1.95705201e-02,  6.30064402e-04,\n",
              "          2.78018179e-05, -2.13796999e-02, -1.27708195e-02,\n",
              "         -2.20560934e-03,  6.71758726e-02],\n",
              "        [ 4.82265372e-03, -6.96517751e-02,  3.43040749e-02,\n",
              "         -1.06468317e-04, -6.71342239e-02, -1.78647608e-01,\n",
              "          7.32634543e-03, -8.88278782e-02],\n",
              "        [ 2.24170871e-02,  4.65865582e-02,  2.95169256e-03,\n",
              "         -3.43731162e-03,  1.14842281e-01,  3.05271707e-02,\n",
              "         -1.53909102e-02, -5.23133352e-02]],\n",
              "\n",
              "       [[ 6.04932755e-03,  3.05475332e-02, -8.72041956e-02,\n",
              "          6.20854506e-03, -6.75051808e-02, -4.41703834e-02,\n",
              "         -1.17088947e-02, -2.26770193e-04],\n",
              "        [ 4.86183120e-03, -9.58268493e-02,  1.89339891e-01,\n",
              "          3.73162478e-02,  4.31193709e-02, -4.37605754e-02,\n",
              "         -6.27177255e-03, -1.20115066e-02],\n",
              "        [ 3.56865115e-02, -5.56173027e-02, -1.73845634e-01,\n",
              "          1.26143061e-02, -3.07912901e-02,  9.22048539e-02,\n",
              "          1.68408491e-02,  5.22881979e-03]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Luu8m60Awc-n"
      },
      "source": [
        "## 1.2Attention Net定义"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxYuTD02rlWc"
      },
      "source": [
        "mode = 'x'\n",
        "out_layer = Dense(units=1, activation=None)\n",
        "\n",
        "def attention_unit(inputs):\n",
        "  att_units = 8\n",
        "  att_w = Dense(units=att_units, activation='relu', use_bias=True)\n",
        "  att = Dense(units=1, activation=None)\n",
        "  dropout = Dropout(0.1, trainable=True)\n",
        "  a = att(att_w(inputs)) # (None, (len(sparse) * len(sparse) - 1) / 2, 1)\n",
        "  att_weight = tf.nn.softmax(a, axis=1)  # (None, (len(sparse) * len(sparse) - 1) / 2, 1)\n",
        "  outputs = tf.reduce_sum(inputs * att_weight, axis=1)  # (None, embed_dim)\n",
        "  return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpXnCUiqwmJC"
      },
      "source": [
        "## 1.3Attention聚合输出"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-xiG227pO_l",
        "outputId": "aa782edd-af3a-4587-a727-dd6324a5f75f"
      },
      "source": [
        "if mode == 'max':\n",
        "  x = tf.reduce_sum(pwi_out, axis=1)\n",
        "elif mode == 'avg':\n",
        "  x = tf.reduce_mean(pwi_out, axis=1)\n",
        "else:\n",
        "  x = attention_unit(pwi_out)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 8), dtype=float32, numpy=\n",
              "array([[ 0.02641316, -0.01140372, -0.03234252, -0.00577684, -0.02759554,\n",
              "        -0.01499589, -0.02228822, -0.07971201],\n",
              "       [ 0.0364208 , -0.01493863,  0.0127764 , -0.00114742,  0.00756033,\n",
              "        -0.05475701, -0.00328075, -0.02454796],\n",
              "       [ 0.01541533, -0.03976187, -0.02397325,  0.0186403 , -0.01870697,\n",
              "         0.00087633, -0.00050281, -0.00234059]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR9O2fscx7N5"
      },
      "source": [
        "## 1.4AFM输出\n",
        ">可输出logits或者得到原始向量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8NbBaHp4uKN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "409c5013-3cdd-4dc8-f433-c736c4137b57"
      },
      "source": [
        "tf.nn.sigmoid(out_layer(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
              "array([[0.51916593],\n",
              "       [0.49950588],\n",
              "       [0.5109924 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs0XxUlny9Dk"
      },
      "source": [
        "# 2.id粒度交叉与Attention\n",
        ">同一featureField下的id交互"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saPuKRvnzaAB",
        "outputId": "3743ae90-d782-428f-f8a4-96e536274e9e"
      },
      "source": [
        "feature_emb = tf.concat([seq_emb_dict['3101_embedding'],seq_emb_dict['target_embedding']], axis=1)\n",
        "feature_emb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3, 8), dtype=float32, numpy=\n",
              "array([[[ 0.10851995, -0.21175861, -0.19599624,  0.17972289,\n",
              "         -0.20250568,  0.42037708,  0.23111723, -0.12334363],\n",
              "        [-0.1015612 ,  0.1568562 ,  0.24457736, -0.1897932 ,\n",
              "          0.65568906,  0.22437245,  0.07827882,  0.16095835],\n",
              "        [-0.2918778 ,  0.11703963, -0.48035088,  0.08511736,\n",
              "         -0.3667829 ,  0.16048141,  0.50944287, -0.47667384]],\n",
              "\n",
              "       [[-0.16384096,  0.18525474, -0.07343411,  0.19164915,\n",
              "         -0.4320993 ,  0.32238504, -0.01347423,  0.51451015],\n",
              "        [-0.1015612 ,  0.1568562 ,  0.24457736, -0.1897932 ,\n",
              "          0.65568906,  0.22437245,  0.07827882,  0.16095835],\n",
              "        [-0.03634223, -0.40718824,  0.40088144, -0.1147316 ,\n",
              "         -0.60051256, -0.6534803 ,  0.22610572, -0.26301116]],\n",
              "\n",
              "       [[-0.0574158 ,  0.45883518, -0.61636484, -0.2710455 ,\n",
              "          0.6149231 , -0.2895744 ,  0.13206907,  0.0456478 ],\n",
              "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
              "          0.        ,  0.        ,  0.        ,  0.        ],\n",
              "        [-0.16935515, -0.41769618, -0.614376  , -0.27535042,\n",
              "          0.14024313,  0.3022406 , -0.09497716, -0.5262688 ]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztvbBoCC0R8F",
        "outputId": "785f5c6a-3a06-4eab-a00a-396c83ad00f0"
      },
      "source": [
        "pwi_out = []\n",
        "for r, c in itertools.combinations(range(tf.shape(feature_emb)[1]),2):\n",
        "  # print(feature_emb[:,r])\n",
        "  pwi = feature_emb[:,r] * feature_emb[:,c]\n",
        "  pwi_out.append(tf.expand_dims(pwi,axis=1))\n",
        "pwi_out = tf.concat(pwi_out, axis=1)\n",
        "pwi_out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3, 8), dtype=float32, numpy=\n",
              "array([[[-0.01102142, -0.03321565, -0.04793624, -0.03411018,\n",
              "         -0.13278076,  0.09432103,  0.01809159, -0.01985319],\n",
              "        [-0.03167456, -0.02478415,  0.09414697,  0.01529754,\n",
              "          0.07427562,  0.06746271,  0.11774103,  0.05879468],\n",
              "        [ 0.02964346,  0.01835839, -0.11748295, -0.0161547 ,\n",
              "         -0.24049553,  0.03600761,  0.03987859, -0.07672463]],\n",
              "\n",
              "       [[ 0.01663989,  0.02905835, -0.01796032, -0.0363737 ,\n",
              "         -0.28332278,  0.07233432, -0.00105475,  0.08281471],\n",
              "        [ 0.00595435, -0.07543355, -0.02943837, -0.02198821,\n",
              "          0.25948107, -0.21067227, -0.0030466 , -0.13532192],\n",
              "        [ 0.00369096, -0.06387   ,  0.09804653,  0.02177528,\n",
              "         -0.3937495 , -0.14662297,  0.01769929, -0.04233384]],\n",
              "\n",
              "       [[-0.        ,  0.        , -0.        , -0.        ,\n",
              "          0.        , -0.        ,  0.        ,  0.        ],\n",
              "        [ 0.00972366, -0.1916537 ,  0.37867978,  0.0746325 ,\n",
              "          0.08623874, -0.08752115, -0.01254355, -0.02402301],\n",
              "        [-0.        , -0.        , -0.        , -0.        ,\n",
              "          0.        ,  0.        , -0.        , -0.        ]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd06lKgY1vCz"
      },
      "source": [
        "## 2.1Attention计算与输出"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dez6hxyezGzm",
        "outputId": "9365e3e6-8c05-4427-ec6b-e64b98f27021"
      },
      "source": [
        "x = attention_unit(pwi_out)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 8), dtype=float32, numpy=\n",
              "array([[-0.00225289, -0.01180861, -0.03121676, -0.01285173, -0.11074847,\n",
              "         0.06496987,  0.0556797 , -0.01733296],\n",
              "       [ 0.00848957, -0.03857558,  0.01980671, -0.01082109, -0.14439084,\n",
              "        -0.0991254 ,  0.00500599, -0.03372357],\n",
              "       [ 0.00307262, -0.06056136,  0.11966042,  0.0235834 ,  0.0272509 ,\n",
              "        -0.02765613, -0.00396368, -0.00759112]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yisJn46r14Ch",
        "outputId": "044699bc-6744-4231-c4e7-aaed97c5f0d1"
      },
      "source": [
        "tf.nn.sigmoid(out_layer(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
              "array([[0.50350255],\n",
              "       [0.4885404 ],\n",
              "       [0.49196237]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnfuJMfe2Gt9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}