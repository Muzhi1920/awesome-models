{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import array_ops,math_ops,nn_ops,gen_array_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gen_array_ops在矩阵变换中，使用到了生成op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 矩阵维度\n",
    "## 维度变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=int32, numpy=\n",
       "array([[1, 2, 3, 4],\n",
       "       [4, 3, 2, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 1, 1, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = tf.constant([[1,2,3,4],[4,3,2,1],[0,0,1,0],[1,1,1,0]])\n",
    "input_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshape\n",
    "1. 返回同序，同值的Tensor；除非新shape\n",
    "2. -1，按照其他维度计算后得到对应维度；\n",
    "3. [-1]意味着拍平为一维；最多一个-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 8), dtype=int32, numpy=\n",
       "array([[1, 2, 3, 4, 4, 3, 2, 1],\n",
       "       [0, 0, 1, 0, 1, 1, 1, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(input_tensor,[2,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expand_dims\n",
    "扩展维度\n",
    "1. input\n",
    "2. axis 哪个维度上扩展\n",
    "3. dim deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 2, 3, 2), dtype=float32, numpy=\n",
       " array([[[[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       " \n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 1, 3, 2), dtype=float32, numpy=\n",
       " array([[[[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 3, 2, 1), dtype=float32, numpy=\n",
       " array([[[[0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.]]],\n",
       " \n",
       " \n",
       "        [[[0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.]]]], dtype=float32)>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = tf.zeros([2,3,2])\n",
    "tf.expand_dims(image, axis=0),tf.expand_dims(image, axis=1),tf.expand_dims(image, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### squeeze\n",
    "1. 删除size为1的维度；\n",
    "2. 删除指定位置的维度，要求size也为1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 2, 1, 3, 1, 1), dtype=float32, numpy=\n",
       " array([[[[[[1.]],\n",
       " \n",
       "           [[1.]],\n",
       " \n",
       "           [[1.]]]],\n",
       " \n",
       " \n",
       " \n",
       "         [[[[1.]],\n",
       " \n",
       "           [[1.]],\n",
       " \n",
       "           [[1.]]]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       " array([[1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=float32)>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.ones([1, 2, 1, 3, 1, 1])\n",
    "t,array_ops.squeeze(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 3, 1), dtype=float32, numpy=\n",
       "array([[[[1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(t, [2, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shape/size/rank\n",
    "1. 返回Tensor的shape;\n",
    "2. size(num_elements)\n",
    "3. 返回秩；Tensor和矩阵的秩不同；Tensor的秩是指获取到元素时，所需要的索引数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=int32, numpy=array([3, 2, 3], dtype=int32)>,\n",
       " [<tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 3], dtype=int32)>,\n",
       "  <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 3], dtype=int32)>,\n",
       "  <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 3], dtype=int32)>],\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=18>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=3>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]], [[3, 3, 3], [4, 4, 4]]])\n",
    "tf.shape(t), tf.shape_n(t),tf.size(t),tf.rank(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### broadcast_dynamic_shape\n",
    "结合不同长度的特征向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([5, 2, 3]),\n",
       " <tf.Tensor: shape=(3,), dtype=int32, numpy=array([5, 2, 3], dtype=int32)>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_x = tf.TensorShape([1, 2, 1])\n",
    "shape_y = tf.TensorShape([5, 1 ,3])\n",
    "tf.broadcast_static_shape(shape_x, shape_y),tf.broadcast_dynamic_shape(shape_x, shape_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\_check_index\n",
    "\"\"\"Check if a given value is a valid index into a tensor；check给定值是否是一个tensor的合法索引\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_ops._check_index(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\_all_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 1, 2], dtype=int32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_ops._all_dimensions(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 矩阵生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zeros/ones\n",
    "1. shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros([3, 4], tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zeros_like/ones_like\n",
    "1. input，输入的tensor；\n",
    "2. 返回和input，相同的zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[0, 0, 0],\n",
       "       [0, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "tf.zeros_like(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hot\n",
    "1. depth：代表one-hot的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 6), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.one_hot([0,4,3,],6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sequence_mask\n",
    "1.隐码个数、维度；\n",
    "2. 按照输入维度，构造隐码；取最大长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=bool, numpy=\n",
       "array([[ True, False, False, False, False],\n",
       "       [ True,  True,  True, False, False],\n",
       "       [ True,  True, False, False, False]])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sequence_mask([1, 3, 2], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 3), dtype=bool, numpy=\n",
       "array([[[ True, False, False],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       [[ True,  True, False],\n",
       "        [False, False, False]]])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sequence_mask([[1, 3],[2,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matrix_diag\n",
    "1. diagonal：对角矩阵的元素；\n",
    "2. k=0；num_rows=-1；num_cols=-1；padding_value=0；align=\"RIGHT_LEFT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4, 4), dtype=int32, numpy=\n",
       "array([[[1, 0, 0, 0],\n",
       "        [0, 2, 0, 0],\n",
       "        [0, 0, 3, 0],\n",
       "        [0, 0, 0, 4]],\n",
       "\n",
       "       [[5, 0, 0, 0],\n",
       "        [0, 6, 0, 0],\n",
       "        [0, 0, 7, 0],\n",
       "        [0, 0, 0, 8]]], dtype=int32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagonal = [[1, 2, 3, 4],[5, 6, 7, 8]]\n",
    "array_ops.matrix_diag(diagonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4, 4), dtype=int32, numpy=\n",
       "array([[[0, 1, 0, 0],\n",
       "        [0, 0, 2, 0],\n",
       "        [0, 0, 0, 3],\n",
       "        [0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 4, 0, 0],\n",
       "        [0, 0, 5, 0],\n",
       "        [0, 0, 0, 6],\n",
       "        [0, 0, 0, 0]]], dtype=int32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A superdiagonal (per batch).\n",
    "diagonal = [[1, 2, 3],[4, 5, 6]]\n",
    "array_ops.matrix_diag(diagonal, k = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 3, 3), dtype=int32, numpy=\n",
       " array([[[1, 9, 0],\n",
       "         [0, 2, 0],\n",
       "         [0, 4, 3]],\n",
       " \n",
       "        [[6, 3, 0],\n",
       "         [0, 7, 0],\n",
       "         [0, 9, 9]]], dtype=int32)>,\n",
       " '看不懂，后面其他也看不懂')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A tridiagonal band (per batch).\n",
    "diagonals = [[[8, 9, 0],[1, 2, 3],[0, 4, 5]],\n",
    "                      [[2, 3, 0],[6, 7, 9],[0, 9, 1]]]\n",
    "array_ops.matrix_diag(diagonals, k = (-1, 1)),\"看不懂，后面其他也看不懂\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fill\n",
    "填充值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[1, 1, 1],\n",
       "       [1, 1, 1]], dtype=int32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.fill([2, 3], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gather/batch_gather\n",
    "1. 按照indices，收集params；拼接成新的tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sv_feed/yuyinxiao/miniconda2/envs/rank_env/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
      "Instructions for updating:\n",
      "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(7,), dtype=int32, numpy=array([1, 2, 3, 4, 0, 5, 0], dtype=int32)>,\n",
       " <tf.Tensor: shape=(7,), dtype=int32, numpy=array([1, 2, 3, 4, 0, 5, 0], dtype=int32)>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3, 4, 5, 0, 0, 0,1, 2, 0, 0, 0, 0, 0, 0,1, 2, 3, 4, 0, 0, 0, 0,1, 2, 3, 4, 5, 6, 7, 8]\n",
    "b = [0,1,2,3,7,4,10]\n",
    "array_ops.gather(a,b),array_ops.batch_gather(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor_scatter_nd_update\n",
    "1. 按照索引，替换tensor的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(7, 1), dtype=int32, numpy=\n",
       " array([[ 0],\n",
       "        [ 1],\n",
       "        [ 2],\n",
       "        [ 3],\n",
       "        [ 7],\n",
       "        [ 4],\n",
       "        [10]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
       " array([      9,      99,     999,    9999,  999999,       0,       0,\n",
       "          99999,       1,       2, 9999999,       0,       0,       0,\n",
       "              0,       0,       1,       2,       3,       4,       0,\n",
       "              0,       0,       0,       1,       2,       3,       4,\n",
       "              5,       6,       7,       8], dtype=int32)>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices= array_ops.reshape(b,[-1,1])\n",
    "updates = [9, 99, 999, 9999, 99999, 999999, 9999999]\n",
    "indices,array_ops.tensor_scatter_nd_update(a, indices, updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### identity\n",
    "它是通过在计算图内部创建 send / recv节点来引用或复制变量的，最主要的用途就是更好的控制在不同设备间传递变量的值."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=5>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=5>,\n",
       " <tf.Variable 'UnreadVariable' shape=() dtype=int32, numpy=6>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.Variable(5)\n",
    "print(a)\n",
    "a_identity = tf.identity(a)\n",
    "a_identity,a.assign_add(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 矩阵比较"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setdiff1d\n",
    "取两个Tensor的差集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-23-d032a7d2c628>:3: setdiff1d (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to tf.sets.difference().\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ListDiff(out=<tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 4, 6], dtype=int32)>, idx=<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 3, 5], dtype=int32)>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1, 2, 3, 4, 5, 6]\n",
    "y = [1, 3, 5]\n",
    "array_ops.setdiff1d(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### boolean_mask\n",
    "按照boolean的mask数组，取对应维度的tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([0, 2], dtype=int32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1-D example\n",
    "tensor = [0, 1, 2, 3]\n",
    "mask = [True, False, True, False]\n",
    "tf.boolean_mask(tensor, mask)  # [0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[1, 2],\n",
       "       [5, 6]], dtype=int32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2-D example\n",
    "tensor = [[1, 2], [3, 4], [5, 6]]\n",
    "mask = [True, False, True]\n",
    "tf.boolean_mask(tensor, mask)  # [[1, 2], [5, 6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sparse_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'未发现用处'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_sparse = tf.sparse.SparseTensor(indices=[[0,0],[0,1],[1,0],[2,0],[2,2],[3,0],[4,1]],\n",
    "                                    values=[1213,1212,20,1,12,34,32],\n",
    "                                    dense_shape=[5,3])\n",
    "cur_sparse,tf.sparse.to_dense(cur_sparse)\n",
    "# res = tf.sparse.mask(cur_sparse, [0,1])\n",
    "# res.indices,res.values  # [2, 10]\n",
    "\"未发现用处\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unique/with_counts\n",
    "1. 得到某tensor的集合；\n",
    "2. 返回集合，及其对应的下标；可按照下标恢复原tensor；\n",
    "3. 返回每个元素的频次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(5,), dtype=int32, numpy=array([1, 2, 4, 7, 8], dtype=int32)>,\n",
       " <tf.Tensor: shape=(9,), dtype=int32, numpy=array([0, 0, 1, 2, 2, 2, 3, 4, 4], dtype=int32)>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([1, 1, 2, 4, 4, 4, 7, 8, 8])\n",
    "y,z = tf.unique(x)\n",
    "y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(5,), dtype=int32, numpy=array([1, 2, 4, 7, 8], dtype=int32)>,\n",
       " <tf.Tensor: shape=(9,), dtype=int32, numpy=array([0, 0, 1, 2, 2, 2, 3, 4, 4], dtype=int32)>,\n",
       " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([2, 1, 3, 1, 2], dtype=int32)>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([1, 1, 2, 4, 4, 4, 7, 8, 8])\n",
    "y, idx, count = tf.unique_with_counts(x)\n",
    "y,idx,count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 矩阵变换\n",
    "## 切片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### slice\n",
    "从Tensor中抽取分片;\n",
    "1. `size[i] = input_.dim_size(i) - begin[i]`\n",
    "2. 从`begin`开始, tensor shape表示的size；`size[i]` 表示从第'i'维上所取的元素数\n",
    "3. begin从0开始，size从1开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2, 3), dtype=int32, numpy=\n",
       " array([[[1, 1, 1],\n",
       "         [2, 2, 2]],\n",
       " \n",
       "        [[3, 3, 3],\n",
       "         [4, 4, 4]],\n",
       " \n",
       "        [[5, 5, 5],\n",
       "         [6, 6, 6]]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(1, 1, 3), dtype=int32, numpy=array([[[3, 3, 3]]], dtype=int32)>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[[1, 1, 1], [2, 2, 2]],\n",
    "                   [[3, 3, 3], [4, 4, 4]],\n",
    "                   [[5, 5, 5], [6, 6, 6]]])\n",
    "t,tf.slice(t, [1, 0, 0], [1, 1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2), dtype=int32, numpy=\n",
       "array([[[3, 3],\n",
       "        [4, 4]]], dtype=int32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.slice(t, [1, 0, 0], [1, 2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### strided_sice\n",
    "1. input,begin,end,strides\n",
    "2. 分片大小为size = `(end-begin)/stride`；\n",
    "3. 以当前位置开始，取size大小的矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 3), dtype=int32, numpy=array([[[3, 3, 3]]], dtype=int32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strided_slice(t, [1, 0, 0], [2, 1, 3], [1, 1, 1])\n",
    "# 第一维是开区间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 3), dtype=int32, numpy=\n",
       "array([[[3, 3, 3],\n",
       "        [4, 4, 4]]], dtype=int32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strided_slice(t, [1, 0, 0], [2, 2, 3], [1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 3), dtype=int32, numpy=\n",
       "array([[[4, 4, 4],\n",
       "        [3, 3, 3]]], dtype=int32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strided_slice(t, [1, -1, 0], [2, -3, 3], [1, -1, 1])\n",
    "# 负号，代表[[3],[4]]，倒数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
       " array([[1, 2, 3, 4],\n",
       "        [1, 2, 3, 4]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
       " array([[5, 6, 7, 8],\n",
       "        [5, 6, 7, 8]], dtype=int32)>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对第二维，按照4，4的大小，分成两份\n",
    "x=[[1,2,3,4,5,6,7,8],[1,2,3,4,5,6,7,8]]\n",
    "array_ops.split(x, [4, 4], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 组合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parallel_stack/stack\n",
    "1. parallel不支持bp；stack支持；\n",
    "2. 堆放一个rank-`R`的tensors 为rank-`(R+1)` tensor；\n",
    "3. Given a list of length `N` of tensors of shape `(A, B, C)`;\n",
    "4. if `axis == 0` then the `output` tensor will have the shape `(N, A, B, C)`.\n",
    "5. if `axis == 1` then the `output` tensor will have the shape `(A, N, B, C)`.\n",
    "6. 增加维度的拼接，和concat不同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       " array([[1, 4],\n",
       "        [1, 4]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(3, 2, 2), dtype=int32, numpy=\n",
       " array([[[1, 4],\n",
       "         [1, 4]],\n",
       " \n",
       "        [[2, 5],\n",
       "         [2, 5]],\n",
       " \n",
       "        [[3, 6],\n",
       "         [3, 6]]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
       " array([[[1, 4],\n",
       "         [2, 5],\n",
       "         [3, 6]],\n",
       " \n",
       "        [[1, 4],\n",
       "         [2, 5],\n",
       "         [3, 6]]], dtype=int32)>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[1,4],[1,4]])\n",
    "y = tf.constant([[2,5],[2,5]])\n",
    "z = tf.constant([[3,6],[3,6]])\n",
    "x,tf.stack([x, y, z],axis=0),tf.stack([x, y, z],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unstack\n",
    "1. Unpacks rank-`R` tensor为rank-`(R-1)` tensors；\n",
    "2. given a tensor of shape `(A, B, C, D)`；\n",
    "3. If `axis == 0` then the i'th tensor in `output` is the slice`value[i, :, :, :]` and each tensor in `output` will have shape `(B, C, D)`.\n",
    "4. If `axis == 1` then the i'th tensor in `output` is the slice`value[:, i, :, :]` and each tensor in `output` will have shape `(A, C, D)`.\n",
    "5. 返回解包后的list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 2), dtype=int32, numpy=\n",
       "array([[[1, 4],\n",
       "        [1, 4]],\n",
       "\n",
       "       [[2, 5],\n",
       "        [2, 5]],\n",
       "\n",
       "       [[3, 6],\n",
       "        [3, 6]]], dtype=int32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[1,4],[1,4]])\n",
    "y = tf.constant([[2,5],[2,5]])\n",
    "z = tf.constant([[3,6],[3,6]])\n",
    "a = tf.stack([x, y, z],axis=0)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       " array([[1, 4],\n",
       "        [1, 4]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       " array([[2, 5],\n",
       "        [2, 5]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       " array([[3, 6],\n",
       "        [3, 6]], dtype=int32)>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=tf.unstack(a,axis=0)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concat\n",
    "1. axis，按照某维度拼接；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
       " array([[1, 4, 2, 5, 3, 6],\n",
       "        [1, 4, 2, 5, 3, 6]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(6, 2), dtype=int32, numpy=\n",
       " array([[1, 4],\n",
       "        [1, 4],\n",
       "        [2, 5],\n",
       "        [2, 5],\n",
       "        [3, 6],\n",
       "        [3, 6]], dtype=int32)>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat(b,axis=1),tf.concat(b,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 8), dtype=float32, numpy=\n",
       " array([[ 5.7410979e-01, -7.6293945e-04, -4.7076225e-02, -8.6661029e-01,\n",
       "         -6.0015273e-01, -4.5935416e-01, -9.3237591e-01,  6.4132524e-01]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 8), dtype=float32, numpy=\n",
       " array([[-0.02825642,  0.16726208, -0.68280125,  0.38965058,  0.85696006,\n",
       "          0.28510857,  0.8728919 , -0.494231  ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 8), dtype=float32, numpy=\n",
       " array([[-0.32020926, -0.35197496,  0.9064059 , -0.6801567 ,  0.8475621 ,\n",
       "          0.36474967,  0.45799208, -0.6246288 ]], dtype=float32)>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant(tf.random.uniform([3, 8], -1, 1))\n",
    "s0, s1, s2 = tf.split(x, num_or_size_splits=3, axis=0)\n",
    "s0,s1,s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### repeat\n",
    "1. 输入input\n",
    "2. 重复input的元素\n",
    "3. 沿着某axis进行repeat，空时，reshape成1-D再进行repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=string, numpy=array([b'a', b'a', b'a', b'c', b'c'], dtype=object)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_ops.repeat(['a', 'b', 'c'], repeats=[3, 0, 2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 2), dtype=int32, numpy=\n",
       "array([[1, 2],\n",
       "       [1, 2],\n",
       "       [3, 4],\n",
       "       [3, 4],\n",
       "       [3, 4]], dtype=int32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_ops.repeat([[1, 2], [3, 4]], repeats=[2, 3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=int32, numpy=\n",
       "array([[1, 1, 2, 2, 2],\n",
       "       [3, 3, 4, 4, 4]], dtype=int32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_ops.repeat([[1, 2], [3, 4]], repeats=[2, 3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([3, 3, 3, 3], dtype=int32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_ops.repeat(3, repeats=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8,), dtype=int32, numpy=array([1, 1, 2, 2, 3, 3, 4, 4], dtype=int32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_ops.repeat([[1,2], [3,4]], repeats=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transpose\n",
    "1. 转置\n",
    "2. `perm`it is set to (n-1...0)，输入维度的排列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[1, 4],\n",
       "        [2, 5],\n",
       "        [3, 6]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[1, 4],\n",
       "        [2, 5],\n",
       "        [3, 6]], dtype=int32)>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "tf.transpose(x),tf.transpose(x, perm=[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=complex128, numpy=\n",
       "array([[1.-1.j, 4.-4.j],\n",
       "       [2.-2.j, 5.-5.j],\n",
       "       [3.-3.j, 6.-6.j]])>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 复数，设置conjugate=True，转置且共轭\n",
    "x = tf.constant([[1 + 1j, 2 + 2j, 3 + 3j],\n",
    "                 [4 + 4j, 5 + 5j, 6 + 6j]])\n",
    "tf.transpose(x, conjugate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
       " array([[[ 1,  4],\n",
       "         [ 2,  5],\n",
       "         [ 3,  6]],\n",
       " \n",
       "        [[ 7, 10],\n",
       "         [ 8, 11],\n",
       "         [ 9, 12]]], dtype=int32)>,\n",
       " '没看懂')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[[ 1,  2,  3],\n",
    "                  [ 4,  5,  6]],\n",
    "                 [[ 7,  8,  9],\n",
    "                  [10, 11, 12]]])\n",
    "# Take the transpose of the matrices in dimension-0\n",
    "# (this common operation has a shorthand `linalg.matrix_transpose`)\n",
    "tf.transpose(x, perm=[0, 2, 1]),\"没看懂\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[1, 4],\n",
       "       [2, 5],\n",
       "       [3, 6]], dtype=int32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "tf.linalg.matrix_transpose(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=complex128, numpy=\n",
       "array([[1.-1.j, 4.-4.j],\n",
       "       [2.-2.j, 5.-5.j],\n",
       "       [3.-3.j, 6.-6.j]])>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[1 + 1j, 2 + 2j, 3 + 3j],\n",
    "                 [4 + 4j, 5 + 5j, 6 + 6j]])\n",
    "tf.linalg.matrix_transpose(x, conjugate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 矩阵相乘\n",
    "1. %%time 当前cell执行完所耗时间；\n",
    "2. %time 当前行执行所耗时间\n",
    "3. %timeit 对当前行之行1000次消耗时间的统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.38 ms, sys: 965 µs, total: 3.35 ms\n",
      "Wall time: 2.08 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=complex128, numpy=\n",
       "array([[0. +28.j, 0. +64.j],\n",
       "       [0. +64.j, 0.+154.j]])>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Good!  Transpose is taken at minimal additional cost.\n",
    "tf.matmul(x, x, transpose_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 432 µs, sys: 940 µs, total: 1.37 ms\n",
      "Wall time: 810 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 2), dtype=complex128, numpy=\n",
       " array([[0. +28.j, 0. +64.j],\n",
       "        [0. +64.j, 0.+154.j]])>,\n",
       " '果然！')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Inefficient!\n",
    "tf.matmul(x, tf.linalg.matrix_transpose(x)),\"果然！\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pad\n",
    "1. `paddings`维度 `[n, 2]`，n是tensor的维度. For each dimension D of `input`, `paddings[D, 0]` indicates how\n",
    "many values to add before the contents of `tensor` in that dimension, and `paddings[D, 1]` indicates how many values to add after the contents of `tensor` in that dimension. \n",
    "2. 意思就是padding=[[1,2],[3,4]]，对应上下左右多少个0\n",
    "3. If `mode` is \"REFLECT\" then both `paddings[D, 0]` and `paddings[D, 1]` must be no greater than `tensor.dim_size(D) - 1`. If `mode` is \"SYMMETRIC\" then both `paddings[D, 0]` and `paddings[D, 1]` must be no greater than `tensor.dim_size(D)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 2, 3, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 4, 5, 6, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "paddings = tf.constant([[1,2], [3, 4]])\n",
    "tf.pad(t, paddings, \"CONSTANT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4, 7), dtype=int32, numpy=\n",
       " array([[6, 5, 4, 5, 6, 5, 4],\n",
       "        [3, 2, 1, 2, 3, 2, 1],\n",
       "        [6, 5, 4, 5, 6, 5, 4],\n",
       "        [3, 2, 1, 2, 3, 2, 1]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(4, 7), dtype=int32, numpy=\n",
       " array([[2, 1, 1, 2, 3, 3, 2],\n",
       "        [2, 1, 1, 2, 3, 3, 2],\n",
       "        [5, 4, 4, 5, 6, 6, 5],\n",
       "        [5, 4, 4, 5, 6, 6, 5]], dtype=int32)>,\n",
       " '没看懂')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paddings = tf.constant([[1,1], [2,2]])\n",
    "tf.pad(t, paddings, \"REFLECT\"),tf.pad(t, paddings, \"SYMMETRIC\"),\"没看懂\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 其他"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### edit_distance\n",
    "1. 计算编辑距离：Levenshtein distance between sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 1, 1), dtype=string, numpy=\n",
       " array([[[b'a']],\n",
       " \n",
       "        [[b'b']]], dtype=object)>,\n",
       " <tf.Tensor: shape=(2, 2, 2), dtype=string, numpy=\n",
       " array([[[b'', b''],\n",
       "         [b'a', b'']],\n",
       " \n",
       "        [[b'b', b'c'],\n",
       "         [b'a', b'']]], dtype=object)>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[inf, 1. ],\n",
       "        [0.5, 1. ]], dtype=float32)>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis = tf.SparseTensor([[0, 0, 0],\n",
    "                              [1, 0, 0]],\n",
    "                             [\"a\", \"b\"],(2, 1, 1))\n",
    "truth = tf.SparseTensor([[0, 1, 0],\n",
    "                         [1, 0, 0],\n",
    "                         [1, 0, 1],\n",
    "                         [1, 1, 0]],\n",
    "                        [\"a\", \"b\", \"c\", \"a\"],(2, 2, 2))\n",
    "tf.sparse.to_dense(hypothesis),tf.sparse.to_dense(truth),tf.edit_distance(hypothesis, truth, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### where\n",
    "1. 判断条件，满足则返回x，否则返回y；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reverse_sequence\n",
    "1. 对input，反转设定长度序列\n",
    "2. seq_axis，batch_axis；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 8), dtype=int32, numpy=\n",
       "array([[0, 0, 5, 4, 3, 2, 1, 0],\n",
       "       [2, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [3, 2, 1, 4, 0, 0, 0, 0],\n",
       "       [5, 4, 3, 2, 1, 6, 7, 8]], dtype=int32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_lengths = [7, 2, 3, 5]\n",
    "input_ = [[1, 2, 3, 4, 5, 0, 0, 0], [1, 2, 0, 0, 0, 0, 0, 0],\n",
    "          [1, 2, 3, 4, 0, 0, 0, 0], [1, 2, 3, 4, 5, 6, 7, 8]]\n",
    "output = tf.reverse_sequence(input_, seq_lengths, seq_axis=1, batch_axis=0)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quantize\n",
    "1. 计算分位数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sv_feed/yuyinxiao/miniconda2/envs/rank_env/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201: quantize_v2 (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
      "Instructions for updating:\n",
      "`tf.quantize_v2` is deprecated, please use `tf.quantization.quantize` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuantizeV2(output=<tf.Tensor: shape=(4, 8), dtype=qint32, numpy=\n",
       "array([[-1717986944, -1288490240,  -858993408,  -429496704,           0,\n",
       "        -2147483648, -2147483648, -2147483648],\n",
       "       [-1717986944, -1288490240, -2147483648, -2147483648, -2147483648,\n",
       "        -2147483648, -2147483648, -2147483648],\n",
       "       [-1717986944, -1288490240,  -858993408,  -429496704, -2147483648,\n",
       "        -2147483648, -2147483648, -2147483648],\n",
       "       [-1717986944, -1288490240,  -858993408,  -429496704,           0,\n",
       "          429496832,   858993408,  1288490240]], dtype=int32)>, output_min=<tf.Tensor: shape=(), dtype=float32, numpy=0.0>, output_max=<tf.Tensor: shape=(), dtype=float32, numpy=10.0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_ops.quantize(input_, min_range=0, max_range=10, T=\"qint32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### searchsorted\n",
    "1. sorted_seq：有序序列\n",
    "2. values：\n",
    "3. side：起始查找"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       " array([[1, 2, 2],\n",
       "        [0, 1, 5]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       " array([[1, 2, 4],\n",
       "        [0, 2, 5]], dtype=int32)>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_sequence = [[0, 3, 9, 9, 10],\n",
    "                   [1, 2, 3, 4, 5]]\n",
    "values = [[2, 4, 9],\n",
    "          [0, 2, 6]]\n",
    "a = array_ops.searchsorted(sorted_sequence, values, side=\"left\")\n",
    "b = array_ops.searchsorted(sorted_sequence, values, side=\"right\")\n",
    "a,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fingerprint\n",
    "1. 生成输入的指纹值\n",
    "2. method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 8), dtype=uint8, numpy=\n",
       "array([[191, 100,  99, 247, 252,  22, 120, 249],\n",
       "       [ 84,  24,  96,  84, 195,  82, 124, 105],\n",
       "       [ 15, 219, 106, 105,  88, 163,  17,  93],\n",
       "       [ 92,   8,   0, 238, 168, 146,  54,  37],\n",
       "       [178, 113,  27,   7, 149, 125, 165, 247],\n",
       "       [172, 241, 253,  71,  91, 205, 163, 224]], dtype=uint8)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating result \n",
    "a = [0,1,2,3,4,5]\n",
    "array_ops.fingerprint(a, method = 'farmhash64')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf24(py37)",
   "language": "python",
   "name": "rank_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "291px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
